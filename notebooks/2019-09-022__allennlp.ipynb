{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allennlp\n",
    "from allennlp.predictors.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59248617/59248617 [00:26<00:00, 2209159.35B/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/usr/local/lib/python3.6/dist-packages/allennlp/data/token_indexers/token_characters_indexer.py:56: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n",
      "  UserWarning)\n",
      "WARNING:allennlp.common.util:Spacy models 'en_core_web_sm' not found.  Downloading and installing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_sm\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/coref-model-2018.02.05.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clusters': [[[0, 0], [12, 12]]],\n",
       " 'document': ['Grace',\n",
       "  'is',\n",
       "  'washed',\n",
       "  'up',\n",
       "  'on',\n",
       "  'a',\n",
       "  'beach',\n",
       "  'along',\n",
       "  'with',\n",
       "  'a',\n",
       "  'man',\n",
       "  'whom',\n",
       "  'she',\n",
       "  'can',\n",
       "  'not',\n",
       "  'recollect',\n",
       "  '.'],\n",
       " 'predicted_antecedents': [-1, -1, -1, -1, 3, -1],\n",
       " 'top_spans': [[0, 0], [2, 2], [5, 6], [9, 15], [12, 12], [15, 15]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(document=\"Grace is washed up on a beach along with a man whom she can not recollect .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_string = open(\"../models/ACL2013_Personas/preprocess/corenlp_plot_summaries/10006475.xml\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_etree = ET.fromstring(xml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(xml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_x = doc_etree.find('document').find('coreference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mentions = []\n",
    "for entity_x in coref_x.findall('coreference'):\n",
    "    mentions = []\n",
    "    for mention_x in entity_x.findall('mention'):\n",
    "        m = {}\n",
    "        m['sentence'] = int(mention_x.find('sentence').text) - 1\n",
    "        m['start'] = int(mention_x.find('start').text) - 1\n",
    "        m['end'] = int(mention_x.find('end').text) - 1\n",
    "        m['head'] = int(mention_x.find('head').text) - 1\n",
    "        mentions.append(m)\n",
    "    all_mentions.append(mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'coreference' at 0x7f8e66159ef8>,\n",
       " <Element 'coreference' at 0x7f8e661612c8>,\n",
       " <Element 'coreference' at 0x7f8e66161638>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_x.findall('coreference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<coreference>\n",
      "        <mention representative=\"true\">\n",
      "          <sentence>1</sentence>\n",
      "          <start>13</start>\n",
      "          <end>14</end>\n",
      "          <head>13</head>\n",
      "        </mention>\n",
      "        <mention>\n",
      "          <sentence>2</sentence>\n",
      "          <start>13</start>\n",
      "          <end>14</end>\n",
      "          <head>13</head>\n",
      "        </mention>\n",
      "        <mention>\n",
      "          <sentence>2</sentence>\n",
      "          <start>28</start>\n",
      "          <end>29</end>\n",
      "          <head>28</head>\n",
      "        </mention>\n",
      "      </coreference>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(ET.tostring(coref_x.findall('coreference')[2]).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Grace'),\n",
       " (2, 'is'),\n",
       " (3, 'washed'),\n",
       " (4, 'up'),\n",
       " (5, 'on'),\n",
       " (6, 'a'),\n",
       " (7, 'beach'),\n",
       " (8, 'along'),\n",
       " (9, 'with'),\n",
       " (10, 'a'),\n",
       " (11, 'man'),\n",
       " (12, 'whom'),\n",
       " (13, 'she'),\n",
       " (14, 'can'),\n",
       " (15, 'not'),\n",
       " (16, 'recollect'),\n",
       " (17, '.')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"Grace is washed up on a beach along with a man whom she can not recollect .\"\n",
    "[(x[0]+1, x[1]) for x in enumerate(s1.split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'But'),\n",
       " (2, 'since'),\n",
       " (3, 'it'),\n",
       " (4, 'becomes'),\n",
       " (5, 'quickly'),\n",
       " (6, 'apparent'),\n",
       " (7, 'that'),\n",
       " (8, 'the'),\n",
       " (9, 'man'),\n",
       " (10, 'means'),\n",
       " (11, 'to'),\n",
       " (12, 'kill'),\n",
       " (13, 'her'),\n",
       " (14, ','),\n",
       " (15, 'Grace'),\n",
       " (16, 'is'),\n",
       " (17, 'forced'),\n",
       " (18, 'to'),\n",
       " (19, 'resort'),\n",
       " (20, 'to'),\n",
       " (21, 'extreme'),\n",
       " (22, 'measures'),\n",
       " (23, 'to'),\n",
       " (24, 'stay'),\n",
       " (25, 'alive'),\n",
       " (26, 'while'),\n",
       " (27, 'putting'),\n",
       " (28, 'her'),\n",
       " (29, 'memory'),\n",
       " (30, 'back'),\n",
       " (31, 'together'),\n",
       " (32, '.')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = \"But since it becomes quickly apparent that the man means to kill her , Grace is forced to resort to extreme measures to stay alive while putting her memory back together .\"\n",
    "[(x[0]+1, x[1]) for x in enumerate(s2.split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Grace'),\n",
       " (1, 'is'),\n",
       " (2, 'washed'),\n",
       " (3, 'up'),\n",
       " (4, 'on'),\n",
       " (5, 'a'),\n",
       " (6, 'beach'),\n",
       " (7, 'along'),\n",
       " (8, 'with'),\n",
       " (9, 'a'),\n",
       " (10, 'man'),\n",
       " (11, 'whom'),\n",
       " (12, 'she'),\n",
       " (13, 'can'),\n",
       " (14, 'not'),\n",
       " (15, 'recollect'),\n",
       " (16, '.'),\n",
       " (17, 'But'),\n",
       " (18, 'since'),\n",
       " (19, 'it'),\n",
       " (20, 'becomes'),\n",
       " (21, 'quickly'),\n",
       " (22, 'apparent'),\n",
       " (23, 'that'),\n",
       " (24, 'the'),\n",
       " (25, 'man'),\n",
       " (26, 'means'),\n",
       " (27, 'to'),\n",
       " (28, 'kill'),\n",
       " (29, 'her'),\n",
       " (30, ','),\n",
       " (31, 'Grace'),\n",
       " (32, 'is'),\n",
       " (33, 'forced'),\n",
       " (34, 'to'),\n",
       " (35, 'resort'),\n",
       " (36, 'to'),\n",
       " (37, 'extreme'),\n",
       " (38, 'measures'),\n",
       " (39, 'to'),\n",
       " (40, 'stay'),\n",
       " (41, 'alive'),\n",
       " (42, 'while'),\n",
       " (43, 'putting'),\n",
       " (44, 'her'),\n",
       " (45, 'memory'),\n",
       " (46, 'back'),\n",
       " (47, 'together'),\n",
       " (48, '.')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate((s1 + ' ' + s2).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clusters': [[[0, 0], [12, 12], [29, 29], [31, 31], [44, 44]],\n",
       "  [[9, 15], [24, 25]]],\n",
       " 'document': ['Grace',\n",
       "  'is',\n",
       "  'washed',\n",
       "  'up',\n",
       "  'on',\n",
       "  'a',\n",
       "  'beach',\n",
       "  'along',\n",
       "  'with',\n",
       "  'a',\n",
       "  'man',\n",
       "  'whom',\n",
       "  'she',\n",
       "  'can',\n",
       "  'not',\n",
       "  'recollect',\n",
       "  '.',\n",
       "  'But',\n",
       "  'since',\n",
       "  'it',\n",
       "  'becomes',\n",
       "  'quickly',\n",
       "  'apparent',\n",
       "  'that',\n",
       "  'the',\n",
       "  'man',\n",
       "  'means',\n",
       "  'to',\n",
       "  'kill',\n",
       "  'her',\n",
       "  ',',\n",
       "  'Grace',\n",
       "  'is',\n",
       "  'forced',\n",
       "  'to',\n",
       "  'resort',\n",
       "  'to',\n",
       "  'extreme',\n",
       "  'measures',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'alive',\n",
       "  'while',\n",
       "  'putting',\n",
       "  'her',\n",
       "  'memory',\n",
       "  'back',\n",
       "  'together',\n",
       "  '.'],\n",
       " 'predicted_antecedents': [-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  3,\n",
       "  -1,\n",
       "  -1,\n",
       "  3,\n",
       "  -1,\n",
       "  4,\n",
       "  9,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  6,\n",
       "  -1],\n",
       " 'top_spans': [[0, 0],\n",
       "  [2, 2],\n",
       "  [5, 6],\n",
       "  [9, 15],\n",
       "  [12, 12],\n",
       "  [15, 15],\n",
       "  [20, 20],\n",
       "  [24, 25],\n",
       "  [28, 28],\n",
       "  [29, 29],\n",
       "  [31, 31],\n",
       "  [33, 33],\n",
       "  [35, 35],\n",
       "  [37, 38],\n",
       "  [40, 40],\n",
       "  [41, 41],\n",
       "  [43, 43],\n",
       "  [44, 44],\n",
       "  [44, 45]]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(s1 + ' ' + s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
