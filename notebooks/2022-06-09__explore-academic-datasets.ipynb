{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PolNeAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "import pandas as pd \n",
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import ast\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def get_loc_in_sent(char_idx, sent_lens_cumsum):\n",
    "    if not isinstance(char_idx, int):\n",
    "        char_idx = int(char_idx)\n",
    "    \n",
    "    sent_bin = np.digitize(char_idx, sent_len_cumsum)\n",
    "    offset_in_sent = char_idx - sent_len_cumsum[sent_bin - 1]\n",
    "    return sent_bin, offset_in_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = glob.glob('../data/academic-datasets/PolNeAR/data/*/text/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf69f6018104124981acfd6a7d0c7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_text = []\n",
    "all_annotations = []\n",
    "all_sentences = []\n",
    "for text_file in tqdm(text_files):\n",
    "    base_dir, filename = text_file.split('text/')\n",
    "    base_filename = filename.replace('.txt', '')\n",
    "    \n",
    "    ## read text\n",
    "    with open(text_file) as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        sents = list(doc.sents)\n",
    "        text_sents = list(map(str, sents))\n",
    "        sent_len_cumsum = list(map(lambda x: x.end_char, sents))\n",
    "        all_text.append({\n",
    "            'text_id': base_filename,\n",
    "            'text': text,\n",
    "            'sentences': text_sents\n",
    "        })\n",
    "        \n",
    "    ## read annotation\n",
    "    attr_dir = os.path.join(base_dir, 'attributions', '*')\n",
    "    annot_files = list(filter(lambda x: base_filename in x, glob.glob(attr_dir)))\n",
    "    for a in annot_files:\n",
    "        f_id = a.split('/')[-1]        \n",
    "        d = open(a).read()\n",
    "        t = list(map(lambda x: x.split('\\t'), d.split('\\n')))\n",
    "        t = list(filter(lambda x: len(x) > 1, t))\n",
    "        annotated_file = pd.DataFrame(t)\n",
    "\n",
    "        if len(annotated_file) == 0:\n",
    "            continue\n",
    "\n",
    "        annotated_file['source'] = np.nan\n",
    "        annotated_file['start_sentence'] = np.nan\n",
    "        annotated_file['end_sentence'] = np.nan\n",
    "\n",
    "        for row_idx, annotated_id, info_block in (\n",
    "            annotated_file\n",
    "                 .loc[lambda df: df[0].str.contains('T') == True]\n",
    "                 [[0, 1]].itertuples()\n",
    "        ):\n",
    "            chunks = info_block.split(' ')\n",
    "            block_type, char_idx_chunks = chunks[0], ' '.join(chunks[1:])\n",
    "            start_idxs, end_idxs = [], []\n",
    "            \n",
    "            for start_end_chunk in char_idx_chunks.split(';'):\n",
    "                start, end = start_end_chunk.split(' ')\n",
    "                start_sent_idx, char_start = get_loc_in_sent(start, sent_len_cumsum)\n",
    "                end_sent_idx, char_end = get_loc_in_sent(int(end) - 1, sent_len_cumsum)\n",
    "                start_idxs.append(start_sent_idx)\n",
    "                end_idxs.append(end_sent_idx)\n",
    "                \n",
    "            annotated_file.loc[row_idx, 'start_sentence'] = str(start_idxs)\n",
    "            annotated_file.loc[row_idx, 'end_sentence'] = str(end_idxs)\n",
    "\n",
    "        entities = annotated_file.loc[lambda df: df[0].str.contains('E')]\n",
    "        for source_block in entities[1]:\n",
    "            chunks = source_block.strip().split(' ')\n",
    "            ids = list(map(lambda x: x.split(':')[1], chunks))\n",
    "            source_ids = list(filter(lambda x: 'Source' in x, chunks ))\n",
    "            if len(source_ids) == 1:\n",
    "                source_id = source_ids[0].split(':')[1]\n",
    "                source_name = annotated_file.loc[lambda df: df[0] == source_id][2].iloc[0]\n",
    "                annotated_file.loc[lambda df: df[0].isin(ids), 'source'] = source_name \n",
    "            \n",
    "        annotated_file['t_id'] = base_filename\n",
    "        annotated_file['a_id'] = f_id\n",
    "        all_annotations.append(annotated_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations_df = pd.concat(all_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_df = (\n",
    "    pd.DataFrame(all_text)\n",
    "    .assign(sentences=lambda df: df['sentences'].apply(lambda x: list(map(lambda y: y.strip(), x))))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_annotations = (\n",
    "    all_annotations_df\n",
    "     .loc[lambda df: df['source'].notnull()]\n",
    "     .assign(start_sentence=lambda df: df['start_sentence'].apply(ast.literal_eval))\n",
    "     .assign(end_sentence=lambda df: df['end_sentence'].apply(ast.literal_eval))    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     96531\n",
       "2      3277\n",
       "3       132\n",
       "4        50\n",
       "6        12\n",
       "5        12\n",
       "7         2\n",
       "11        2\n",
       "20        1\n",
       "9         1\n",
       "10        1\n",
       "12        1\n",
       "8         1\n",
       "Name: start_sentence, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_annotations['start_sentence'].str.len().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentence_mapping = (\n",
    "    source_annotations\n",
    "     .groupby(['t_id', 'a_id', 'source'])\n",
    "     [['start_sentence', 'end_sentence']]\n",
    "     .aggregate(list)\n",
    "     .applymap(lambda x: list(set([s for l in x for s in l])))\n",
    "     .apply(lambda x: list(set(x['start_sentence'] + x['end_sentence'])), axis=1)\n",
    "     .to_frame('source_sentences')\n",
    "     .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionable_words = [\n",
    "#     'it',\n",
    "#     'which',\n",
    "#     'that',\n",
    "#     'some',\n",
    "#     'you',\n",
    "#     'many'\n",
    "]\n",
    "\n",
    "anonymous_sources = ['some', 'many']\n",
    "messy_sources = ['you', 'that', 'which', 'i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## check questionable sources\n",
    "if False:\n",
    "    t = (source_sentence_mapping\n",
    "             .loc[lambda df: df['source'].isin(questionable_words)]\n",
    "             .merge(all_text_df[['text_id', 'sentences']], left_on='t_id', right_on='text_id')\n",
    "             .assign(source_sentences_text=lambda df: \n",
    "                 df.apply(lambda x: list(map(lambda y: x['sentences'][y], x['source_sentences'])) , axis=1)\n",
    "            )\n",
    "    )\n",
    "\n",
    "    t[['source', 'source_sentences_text']].iloc[3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentence_mapping = source_sentence_mapping.loc[lambda df: ~df['source'].str.lower().isin(messy_sources)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_sentence_lists = (\n",
    "    source_sentence_mapping\n",
    "     .groupby('t_id')[['source', 'source_sentences']]\n",
    "     .aggregate(list)\n",
    "     .assign(source=lambda df: df.apply(lambda x: [[x['source'][i]] * len(s) for i, s in enumerate(x['source_sentences'])], axis=1))\n",
    "     .applymap(lambda x: [s for l in x for s in l])\n",
    "#      .apply(lambda x: list(set(x)))\n",
    "#      .to_frame('quote_sentences')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_sentence_lists_exploded = (quote_sentence_lists\n",
    " .apply(lambda x: list(map(lambda y: {'source': y[0], 'sent': y[1], 't_id': x.name}, zip(x['source'], x['source_sentences']))) , axis=1)\n",
    " .pipe(lambda s: pd.DataFrame([i for x in s for i in x]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_df_exploded = (all_text_df\n",
    " .apply(lambda x: list(map(lambda y: {'s': y[1], 's_idx': y[0], 't_id': x['text_id']}, enumerate(x['sentences']))), axis=1)\n",
    " .pipe(lambda s: pd.DataFrame([i for x in s for i in x]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_quotes_exploded = (\n",
    "    all_text_df_exploded\n",
    "     .merge(quote_sentence_lists_exploded, how='left', left_on=['t_id', 's_idx'], right_on=['t_id', 'sent'])\n",
    "     .set_index('t_id')\n",
    "     .drop(['sent', \n",
    "#             's_idx'\n",
    "           ], axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ids = matched_quotes_exploded.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "d = matched_quotes_exploded.loc[t_ids[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-a1635bb56ede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhtml_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<table>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mhtml_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'<tr><td style=\"background-color: pink\">'\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0msent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'</td><td>'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'</tr>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "html_all = '<table>'\n",
    "for sent, source in d.itertuples(index=False):\n",
    "    if pd.notnull(source):\n",
    "        html_all += '<tr><td style=\"background-color: pink\">' +  sent + '</td><td>' + source + '</tr>'\n",
    "    else:\n",
    "        html_all += '<tr><td>' + sent + '</td><td></td></tr>'\n",
    "html_all += '</table>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Congress could never control President Trump.</td><td></td></tr><tr><td style=\"background-color: pink\">Donald Trump's small band of intellectual defenders can no longer claim that he is good man.</td><td>Donald Trump's small band of intellectual defenders</tr><tr><td style=\"background-color: pink\">Instead, they say his dishonesty and cruelty are acceptable because Congress could check him if he really got out of hand.</td><td>they</tr><tr><td>Like so much else about the Trump campaign, this assertion rests on fantasy.</td><td></td></tr><tr><td style=\"background-color: pink\">An unusual number of Republican lawmakers have come out against him, but most have not.</td><td>An unusual number of Republican lawmakers</tr><tr><td style=\"background-color: pink\">Why are so many siding with a candidate who is so unfit?</td><td>so many</tr><tr><td>High on the list of probable motives is fear of a primary challenge.</td><td></td></tr><tr><td>If GOP lawmakers are cowering before candidate Trump, how could they stand up to President Trump?</td><td></td></tr><tr><td>In addition to his wealth and political base, he would wield the vast power of the executive branch.</td><td></td></tr><tr><td>There is little doubt that he'd use it to punish those who displease him.</td><td></td></tr><tr><td style=\"background-color: pink\">When House Speaker Paul Ryan said he'd no longer defend his bad behavior, Trump responded, \"I would think that Ryan wouldn't be there.\"</td><td>House Speaker Paul Ryan</tr><tr><td style=\"background-color: pink\">When House Speaker Paul Ryan said he'd no longer defend his bad behavior, Trump responded, \"I would think that Ryan wouldn't be there.\"</td><td>Trump</tr><tr><td style=\"background-color: pink\">In light of such threats, Republicans would hesitate to oppose Trump's choices for federal office or hold tough investigations into his management of the government.</td><td>Republicans</tr><tr><td>And it is hard to imagine that they'd reach for the ultimate weapon of impeachment.</td><td></td></tr><tr><td>Maybe congressional Republicans would suddenly get a miraculous infusion of courage and institutional fidelity.</td><td></td></tr><tr><td>But I would not count on it.</td><td></td></tr><tr><td style=\"background-color: pink\">As Ryan acknowledges: \"Under both parties, the presidency keeps breaking the rules, and Congress keeps allowing it to happen.\"</td><td>Ryan</tr><tr><td style=\"background-color: pink\">Even if lawmakers wanted to put some kind of restraint on a Trump administration, they'd have only limited ability to do so.</td><td>lawmakers</tr><tr><td>They could turn down some of his legislative requests, but they'd have a hard time tracking what his administration was doing.</td><td></td></tr><tr><td>The feebleness of congressional oversight has been a problem even under a more-or-less normal person such as Barack Obama.</td><td></td></tr><tr><td>It would be a disaster under a fanatically secretive person such as Trump.</td><td></td></tr><tr><td style=\"background-color: pink\">He won't release his tax returns, and he makes his campaign aides sign non-disclosure agreements.</td><td>his campaign aides</tr><tr><td>The mind boggles at the information that his administration would withhold.</td><td></td></tr><tr><td>Congress has always been at a disadvantage in checking the president's power over foreign policy and national security.</td><td></td></tr><tr><td>Presidents have used military force hundreds of times without congressional approval.</td><td></td></tr><tr><td style=\"background-color: pink\">Congress passed the 1973 War Powers Act to curb this, but military actions by presidents have continued.</td><td>Congress</tr><tr><td style=\"background-color: pink\">The law requires the president to seek congressional authorization within 60 days of starting military action.</td><td>The law</tr><tr><td>This requirement does not limit the president's power to launch a nuclear attack -- a process that would take less than an hour.</td><td></td></tr><tr><td style=\"background-color: pink\">Trump probably does not hope for Armageddon.</td><td>Trump</tr><tr><td>But it is all too plausible that his ignorance and rashness could start a crisis that escalates into a nuclear exchange.</td><td></td></tr><tr><td style=\"background-color: pink\">No one should vote for him in the hope that Congress could stay his hand -- because it can't.</td><td>No one</tr><tr><td>John J. Pitney Jr., a former policy aide to Republicans in Congress, is the Roy P. Crocker Professor of Politics at Claremont McKenna College.</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(matched_quotes_exploded.reset_index()['t_id'].drop_duplicates().tolist())\n",
    "train_test_info = pd.concat([\n",
    "    pd.Series(train).to_frame('files').assign(group='/train/'),\n",
    "    pd.Series(test).to_frame('files').assign(group='/test/')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "(matched_quotes_exploded\n",
    " .assign(source=lambda df: df['source'].isnull())\n",
    " .reset_index()\n",
    " .merge(train_test_info, left_on='t_id', right_on='files', how='left')\n",
    " .assign(t_id=lambda df: df['group'] + df['t_id'])\n",
    " .groupby(['t_id', 's', 's_idx'])['source'].any()\n",
    " .reset_index()\n",
    " .sort_values(['t_id', 's_idx'])\n",
    " [['source', 's', 't_id', 's_idx'] ]\n",
    "  .to_csv('../models/neural_models/quote_detection/data/polnear-training-data-stage-1.tsv', index=False, sep='\\t')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'notebook'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook.__package__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Author Roger Stone',\n",
       " 'Breitbart Jerusalem editor Aaron Klein',\n",
       " 'Breitbart London’s Raheem Kassam',\n",
       " 'Breitbart Texas editor Brandon Darby',\n",
       " 'Dave Gorab',\n",
       " 'Investigative reporter\\xa0Julia Hahn',\n",
       " 'Pope Francis']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = (source_sentence_mapping\n",
    " .groupby(['t_id', 'a_id'])\n",
    " ['source'].aggregate(list).iloc[6]\n",
    ")\n",
    "\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'Former Secretary of State and Democratic presidential frontrunner Hillary Clinton'\n",
    "t = 'Author Roger Stone'\n",
    "t = t3[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = list(nlp(t).ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Breitbart London’s, Raheem Kassam]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = ents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PERSON'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PERSON', 'PERSON']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x.label_, ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>source</th>\n",
       "      <th>source_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wash-post_2016-10-19_so-guess-who-s-the-demogo...</td>\n",
       "      <td>So guess who's the Demogorgon in this scenario...</td>\n",
       "      <td>[So guess who's the Demogorgon in this scenari...</td>\n",
       "      <td>[Clinton, He, His office, Liberals, Newt Gingr...</td>\n",
       "      <td>[32, 35, 10, 41, 15, 9, 38, 7, 28, 36, 32, 33,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breitbart_2016-11-02_asian-markets-on-edge-on-...</td>\n",
       "      <td>Asian markets on edge on US election uncertain...</td>\n",
       "      <td>[Asian markets on edge on US election uncertai...</td>\n",
       "      <td>[Chris Weston, chief market strategist in Melb...</td>\n",
       "      <td>[5, 6, 7, 19, 4, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>west-journal_2016-10-11_donald-trump-claims-th...</td>\n",
       "      <td>Donald Trump Claims ‘The Shackles’ Have Now Be...</td>\n",
       "      <td>[Donald Trump Claims ‘The Shackles’ Have Now B...</td>\n",
       "      <td>[Donald Trump, House Speaker Paul Ryan, Joshua...</td>\n",
       "      <td>[0, 5, 17, 18, 16, 1, 8, 9, 15, 11, 4, 6, 10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usa-today_2016-10-26_congress-could-never-cont...</td>\n",
       "      <td>Congress could never control President Trump.\\...</td>\n",
       "      <td>[Congress could never control President Trump....</td>\n",
       "      <td>[An unusual number of Republican lawmakers, Co...</td>\n",
       "      <td>[4, 24, 1, 10, 29, 11, 15, 25, 10, 27, 20, 16,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>west-journal_2016-10-19_lone-player-stands-dur...</td>\n",
       "      <td>Lone Player Stands During National Anthem Whil...</td>\n",
       "      <td>[Lone Player Stands During National Anthem, Wh...</td>\n",
       "      <td>[Brewer, Jewell Young, a Decatur resident, Jew...</td>\n",
       "      <td>[6, 20, 21, 22, 14, 12, 26, 29, 11, 23, 19, 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>politico_2016-09-30_flight-attendants-union-en...</td>\n",
       "      <td>Flight attendants' union endorses Clinton.\\n\\n...</td>\n",
       "      <td>[Flight attendants' union endorses Clinton., A...</td>\n",
       "      <td>[A union representing flight attendants, Fligh...</td>\n",
       "      <td>[1, 0, 5, 3, 2, 6, 1, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>breitbart_2016-03-11_activists-who-lit-syria-r...</td>\n",
       "      <td>Activists who lit Syria revolt washed away in ...</td>\n",
       "      <td>[Activists who lit Syria revolt washed away in...</td>\n",
       "      <td>[He, He, He, Jimmy Shahinian, a 28-year-old ac...</td>\n",
       "      <td>[32, 26, 39, 3, 4, 33, 34, 35, 27, 28, 29, 22,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>breitbart_2016-03-11_africa-builds-expertise-i...</td>\n",
       "      <td>Africa builds expertise in science, tech, engi...</td>\n",
       "      <td>[Africa builds expertise in science, tech, eng...</td>\n",
       "      <td>[Alta Schutte, Gitau, Gitau, who specializes i...</td>\n",
       "      <td>[2, 43, 33, 32, 10, 17, 28, 44, 7, 13, 14, 36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>breitbart_2016-03-11_activists-brick-up-entran...</td>\n",
       "      <td>Activists Brick Up Entrance To Migrants-Only P...</td>\n",
       "      <td>[Activists Brick Up Entrance To Migrants-Only ...</td>\n",
       "      <td>[A source from the German Identitarian Movemen...</td>\n",
       "      <td>[18, 19, 22, 21, 23, 1, 7, 6, 8, 4, 24, 17, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>breitbart_2016-03-11_afghanistan-thrash-zimbab...</td>\n",
       "      <td>Afghanistan thrash Zimbabwe in World Twenty20....</td>\n",
       "      <td>[Afghanistan thrash Zimbabwe in World Twenty20...</td>\n",
       "      <td>[Nabi, The duo, Nabi, Nabi, Nabi, Nabi, Nabi, ...</td>\n",
       "      <td>[7, 6, 7, 7, 7, 7, 7, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text_id  \\\n",
       "0     wash-post_2016-10-19_so-guess-who-s-the-demogo...   \n",
       "1     breitbart_2016-11-02_asian-markets-on-edge-on-...   \n",
       "2     west-journal_2016-10-11_donald-trump-claims-th...   \n",
       "3     usa-today_2016-10-26_congress-could-never-cont...   \n",
       "4     west-journal_2016-10-19_lone-player-stands-dur...   \n",
       "...                                                 ...   \n",
       "1007  politico_2016-09-30_flight-attendants-union-en...   \n",
       "1008  breitbart_2016-03-11_activists-who-lit-syria-r...   \n",
       "1009  breitbart_2016-03-11_africa-builds-expertise-i...   \n",
       "1010  breitbart_2016-03-11_activists-brick-up-entran...   \n",
       "1011  breitbart_2016-03-11_afghanistan-thrash-zimbab...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     So guess who's the Demogorgon in this scenario...   \n",
       "1     Asian markets on edge on US election uncertain...   \n",
       "2     Donald Trump Claims ‘The Shackles’ Have Now Be...   \n",
       "3     Congress could never control President Trump.\\...   \n",
       "4     Lone Player Stands During National Anthem Whil...   \n",
       "...                                                 ...   \n",
       "1007  Flight attendants' union endorses Clinton.\\n\\n...   \n",
       "1008  Activists who lit Syria revolt washed away in ...   \n",
       "1009  Africa builds expertise in science, tech, engi...   \n",
       "1010  Activists Brick Up Entrance To Migrants-Only P...   \n",
       "1011  Afghanistan thrash Zimbabwe in World Twenty20....   \n",
       "\n",
       "                                              sentences  \\\n",
       "0     [So guess who's the Demogorgon in this scenari...   \n",
       "1     [Asian markets on edge on US election uncertai...   \n",
       "2     [Donald Trump Claims ‘The Shackles’ Have Now B...   \n",
       "3     [Congress could never control President Trump....   \n",
       "4     [Lone Player Stands During National Anthem, Wh...   \n",
       "...                                                 ...   \n",
       "1007  [Flight attendants' union endorses Clinton., A...   \n",
       "1008  [Activists who lit Syria revolt washed away in...   \n",
       "1009  [Africa builds expertise in science, tech, eng...   \n",
       "1010  [Activists Brick Up Entrance To Migrants-Only ...   \n",
       "1011  [Afghanistan thrash Zimbabwe in World Twenty20...   \n",
       "\n",
       "                                                 source  \\\n",
       "0     [Clinton, He, His office, Liberals, Newt Gingr...   \n",
       "1     [Chris Weston, chief market strategist in Melb...   \n",
       "2     [Donald Trump, House Speaker Paul Ryan, Joshua...   \n",
       "3     [An unusual number of Republican lawmakers, Co...   \n",
       "4     [Brewer, Jewell Young, a Decatur resident, Jew...   \n",
       "...                                                 ...   \n",
       "1007  [A union representing flight attendants, Fligh...   \n",
       "1008  [He, He, He, Jimmy Shahinian, a 28-year-old ac...   \n",
       "1009  [Alta Schutte, Gitau, Gitau, who specializes i...   \n",
       "1010  [A source from the German Identitarian Movemen...   \n",
       "1011  [Nabi, The duo, Nabi, Nabi, Nabi, Nabi, Nabi, ...   \n",
       "\n",
       "                                       source_sentences  \n",
       "0     [32, 35, 10, 41, 15, 9, 38, 7, 28, 36, 32, 33,...  \n",
       "1                                  [5, 6, 7, 19, 4, 18]  \n",
       "2     [0, 5, 17, 18, 16, 1, 8, 9, 15, 11, 4, 6, 10, ...  \n",
       "3     [4, 24, 1, 10, 29, 11, 15, 25, 10, 27, 20, 16,...  \n",
       "4     [6, 20, 21, 22, 14, 12, 26, 29, 11, 23, 19, 24...  \n",
       "...                                                 ...  \n",
       "1007                        [1, 0, 5, 3, 2, 6, 1, 2, 3]  \n",
       "1008  [32, 26, 39, 3, 4, 33, 34, 35, 27, 28, 29, 22,...  \n",
       "1009  [2, 43, 33, 32, 10, 17, 28, 44, 7, 13, 14, 36,...  \n",
       "1010  [18, 19, 22, 21, 23, 1, 7, 6, 8, 4, 24, 17, 15...  \n",
       "1011                           [7, 6, 7, 7, 7, 7, 7, 6]  \n",
       "\n",
       "[1008 rows x 5 columns]"
      ]
     },
     "execution_count": 986,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = all_text_df.merge(quote_sentence_lists, right_index=True, left_on='text_id')\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134523, 8)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_annotations_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attribution              25382\n",
       "Attribution-no-source     1955\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_annotations_df\n",
    " .loc[lambda df: df[0].str.contains('T')]\n",
    " .loc[lambda df: df[1].str.contains('Attribution')==True][1]\n",
    " .str.split(' ')\n",
    " .str.get(0)\n",
    " .str.strip()\n",
    " .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seemed                          48\n",
       "is expected                     43\n",
       "appeared                        41\n",
       "seems                           36\n",
       "Asked                           36\n",
       "                                ..\n",
       "growing concern about            1\n",
       "had been previously reported     1\n",
       "recognition                      1\n",
       "recognizing                      1\n",
       "was designated as                1\n",
       "Name: 2, Length: 1243, dtype: int64"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_annotations_df\n",
    " .loc[lambda df: df[0].str.contains('T')]\n",
    " .loc[lambda df: df[1].str.contains('Attribution-no-source')==True]\n",
    " [2].value_counts()\n",
    "#  .str.split(' ')\n",
    "#  .str.get(0)\n",
    "#  .str.strip()\n",
    "#  .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>source</th>\n",
       "      <th>start_sentence</th>\n",
       "      <th>end_sentence</th>\n",
       "      <th>t_id</th>\n",
       "      <th>a_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>Cue 3 8</td>\n",
       "      <td>guess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>wash-post_2016-10-19_so-guess-who-s-the-demogo...</td>\n",
       "      <td>wash-post_2016-10-19_so-guess-who-s-the-demogo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>Content 9 46</td>\n",
       "      <td>who's the Demogorgon in this scenario</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>wash-post_2016-10-19_so-guess-who-s-the-demogo...</td>\n",
       "      <td>wash-post_2016-10-19_so-guess-who-s-the-demogo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>Attribution-no-source 3 8</td>\n",
       "      <td>guess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>wash-post_2016-10-19_so-guess-who-s-the-demogo...</td>\n",
       "      <td>wash-post_2016-10-19_so-guess-who-s-the-demogo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E1</td>\n",
       "      <td>Attribution-no-source:T3 Content:T2 Cue:T1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wash-post_2016-10-19_so-guess-who-s-the-demogo...</td>\n",
       "      <td>wash-post_2016-10-19_so-guess-who-s-the-demogo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T4</td>\n",
       "      <td>Source 121 142</td>\n",
       "      <td>government scientists</td>\n",
       "      <td>government scientists</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>wash-post_2016-10-19_so-guess-who-s-the-demogo...</td>\n",
       "      <td>wash-post_2016-10-19_so-guess-who-s-the-demogo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>Content 1124 1236</td>\n",
       "      <td>“Very happy with my performance, especially in...</td>\n",
       "      <td>Nabi</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>breitbart_2016-03-11_afghanistan-thrash-zimbab...</td>\n",
       "      <td>breitbart_2016-03-11_afghanistan-thrash-zimbab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>Cue 1237 1241</td>\n",
       "      <td>said</td>\n",
       "      <td>Nabi</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>breitbart_2016-03-11_afghanistan-thrash-zimbab...</td>\n",
       "      <td>breitbart_2016-03-11_afghanistan-thrash-zimbab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>Source 1242 1246</td>\n",
       "      <td>Nabi</td>\n",
       "      <td>Nabi</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>breitbart_2016-03-11_afghanistan-thrash-zimbab...</td>\n",
       "      <td>breitbart_2016-03-11_afghanistan-thrash-zimbab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>Attribution 1237 1241</td>\n",
       "      <td>said</td>\n",
       "      <td>Nabi</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>breitbart_2016-03-11_afghanistan-thrash-zimbab...</td>\n",
       "      <td>breitbart_2016-03-11_afghanistan-thrash-zimbab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E1</td>\n",
       "      <td>Attribution:T4 Source:T3 Cue:T2 Content:T1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>breitbart_2016-03-11_afghanistan-thrash-zimbab...</td>\n",
       "      <td>breitbart_2016-03-11_afghanistan-thrash-zimbab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134523 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                                           1  \\\n",
       "0   T1                                     Cue 3 8   \n",
       "1   T2                                Content 9 46   \n",
       "2   T3                   Attribution-no-source 3 8   \n",
       "3   E1  Attribution-no-source:T3 Content:T2 Cue:T1   \n",
       "4   T4                              Source 121 142   \n",
       "..  ..                                         ...   \n",
       "0   T1                           Content 1124 1236   \n",
       "1   T2                               Cue 1237 1241   \n",
       "2   T3                            Source 1242 1246   \n",
       "3   T4                       Attribution 1237 1241   \n",
       "4   E1  Attribution:T4 Source:T3 Cue:T2 Content:T1   \n",
       "\n",
       "                                                    2                 source  \\\n",
       "0                                               guess                    NaN   \n",
       "1               who's the Demogorgon in this scenario                    NaN   \n",
       "2                                               guess                    NaN   \n",
       "3                                                None                    NaN   \n",
       "4                               government scientists  government scientists   \n",
       "..                                                ...                    ...   \n",
       "0   “Very happy with my performance, especially in...                   Nabi   \n",
       "1                                                said                   Nabi   \n",
       "2                                                Nabi                   Nabi   \n",
       "3                                                said                   Nabi   \n",
       "4                                                None                    NaN   \n",
       "\n",
       "   start_sentence end_sentence  \\\n",
       "0             [0]          [0]   \n",
       "1             [0]          [0]   \n",
       "2             [0]          [0]   \n",
       "3             NaN          NaN   \n",
       "4             [1]          [1]   \n",
       "..            ...          ...   \n",
       "0             [7]          [7]   \n",
       "1             [7]          [7]   \n",
       "2             [7]          [7]   \n",
       "3             [7]          [7]   \n",
       "4             NaN          NaN   \n",
       "\n",
       "                                                 t_id  \\\n",
       "0   wash-post_2016-10-19_so-guess-who-s-the-demogo...   \n",
       "1   wash-post_2016-10-19_so-guess-who-s-the-demogo...   \n",
       "2   wash-post_2016-10-19_so-guess-who-s-the-demogo...   \n",
       "3   wash-post_2016-10-19_so-guess-who-s-the-demogo...   \n",
       "4   wash-post_2016-10-19_so-guess-who-s-the-demogo...   \n",
       "..                                                ...   \n",
       "0   breitbart_2016-03-11_afghanistan-thrash-zimbab...   \n",
       "1   breitbart_2016-03-11_afghanistan-thrash-zimbab...   \n",
       "2   breitbart_2016-03-11_afghanistan-thrash-zimbab...   \n",
       "3   breitbart_2016-03-11_afghanistan-thrash-zimbab...   \n",
       "4   breitbart_2016-03-11_afghanistan-thrash-zimbab...   \n",
       "\n",
       "                                                 a_id  \n",
       "0   wash-post_2016-10-19_so-guess-who-s-the-demogo...  \n",
       "1   wash-post_2016-10-19_so-guess-who-s-the-demogo...  \n",
       "2   wash-post_2016-10-19_so-guess-who-s-the-demogo...  \n",
       "3   wash-post_2016-10-19_so-guess-who-s-the-demogo...  \n",
       "4   wash-post_2016-10-19_so-guess-who-s-the-demogo...  \n",
       "..                                                ...  \n",
       "0   breitbart_2016-03-11_afghanistan-thrash-zimbab...  \n",
       "1   breitbart_2016-03-11_afghanistan-thrash-zimbab...  \n",
       "2   breitbart_2016-03-11_afghanistan-thrash-zimbab...  \n",
       "3   breitbart_2016-03-11_afghanistan-thrash-zimbab...  \n",
       "4   breitbart_2016-03-11_afghanistan-thrash-zimbab...  \n",
       "\n",
       "[134523 rows x 8 columns]"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/academic-datasets/PolNeAR/data/test/attributions/wash-post_2016-10-25_on-campus-trump-backers-have-lea_6b86.ann'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breitbart_2016-10-12_washington-post-backs-hillary-cl.txt\r\n",
      "breitbart_2016-10-13_cnn-s-jake-tapper-on-donna-brazi.txt\r\n",
      "breitbart_2016-10-18_obama-says-trump-modeling-polici.txt\r\n",
      "breitbart_2016-10-19_election-uncertainty-weighs-on-p.txt\r\n",
      "breitbart_2016-10-22_canada-eu-failure-signals-more-b.txt\r\n",
      "breitbart_2016-10-25_the-latest-fbi-ready-to-respond-.txt\r\n",
      "breitbart_2016-10-28_us-stocks-sink-as-fbi-reopens-cl.txt\r\n",
      "breitbart_2016-10-31_sheldon-adelson-commits-million-.txt\r\n",
      "breitbart_2016-11-02_asian-markets-on-edge-on-us-elec.txt\r\n",
      "breitbart_2016-11-05_hillary-clinton-documentary-skip.txt\r\n",
      "breitbart_2016-11-06_clinton-aims-high-trump-goes-har.txt\r\n",
      "breitbart_2016-11-07_wikileaks-hillary-clinton-flatte.txt\r\n",
      "huff-post_2016-10-10_new-poll-gives-hillary-clinton-a.txt\r\n",
      "huff-post_2016-10-12_donald-trump-tells-florida-suppo.txt\r\n",
      "huff-post_2016-10-14_donald-trump-jr-women-who-can-t-.txt\r\n",
      "huff-post_2016-10-21_michaela-angela-davis-it-s-time-.txt\r\n",
      "huff-post_2016-10-25_trump-warns-clinton-policy-on-sy.txt\r\n",
      "huff-post_2016-11-02_north-carolina-state-board-of-el.txt\r\n",
      "huff-post_2016-11-02_obama-calls-on-men-to-reflect-on.txt\r\n",
      "huff-post_2016-11-03_donald-trump-invokes-pervert-ant.txt\r\n",
      "huff-post_2016-11-03_trump-creepily-singles-out-repor.txt\r\n",
      "huff-post_2016-11-05_hillary-clinton-drops-into-detro.txt\r\n",
      "huff-post_2016-11-06_most-voters-don-t-change-their-m.txt\r\n",
      "huff-post_2016-11-07_thanks-to-trump-hillary-clinton-.txt\r\n",
      "nyt_2016-10-14_how-to-mend-the-tax-code-to-clos.txt\r\n",
      "nyt_2016-10-14_shake-up-at-wells-fargo-fails-to.txt\r\n",
      "nyt_2016-10-17_british-bank-abruptly-drops-russ.txt\r\n",
      "nyt_2016-10-20_luring-chinese-investors-with-tr.txt\r\n",
      "nyt_2016-10-23_hillary-clinton-presses-her-adva.txt\r\n",
      "nyt_2016-10-23_making-sense-of-at-t-s-bid-for-t.txt\r\n",
      "nyt_2016-10-24_black-democrats-to-hillary-clint.txt\r\n",
      "nyt_2016-10-30_for-democrats-anthony-weiner-mak.txt\r\n",
      "nyt_2016-10-31_confidence-even-as-hillary-clint.txt\r\n",
      "nyt_2016-11-01_f-b-i-s-email-disclosure-broke-a.txt\r\n",
      "nyt_2016-11-02_why-sexual-harassment-persists-i.txt\r\n",
      "nyt_2016-11-07_markets-watch-closely-as-u-s-ele.txt\r\n",
      "politico_2016-10-08_which-republicans-want-to-fire-t.txt\r\n",
      "politico_2016-10-10_internet-phenomenon-ken-bone-deb.txt\r\n",
      "politico_2016-10-11_trump-lament-on-missing-republic.txt\r\n",
      "politico_2016-10-12_hacked-page-roundup-of-paid-spee.txt\r\n",
      "politico_2016-10-17_wikileaks-claims-state-party-cut.txt\r\n",
      "politico_2016-10-27_trump-s-direct-transfers-to-rnc-.txt\r\n",
      "politico_2016-10-31_justice-department-pledges-quick.txt\r\n",
      "politico_2016-10-31_pence-demands-independent-prosec.txt\r\n",
      "politico_2016-11-02_mccaul-if-elected-hillary-clinto.txt\r\n",
      "politico_2016-11-02_trump-adviser-flynn-gets-agitate.txt\r\n",
      "politico_2016-11-03_state-dept-drops-more-clinton-em.txt\r\n",
      "politico_2016-11-03_trump-generals-don-t-want-her-as.txt\r\n",
      "usa-today_2016-10-10_video-surfaces-first-thing-in-de.txt\r\n",
      "usa-today_2016-10-18_companies-used-clinton-fundraise.txt\r\n",
      "usa-today_2016-10-20_who-won-the-vegas-debate.txt\r\n",
      "usa-today_2016-10-21_depending-on-who-wins-the-electi.txt\r\n",
      "usa-today_2016-10-25_in-florida-s-crucial-county-a-fi.txt\r\n",
      "usa-today_2016-10-25_trump-s-threat-to-sue-women-fits.txt\r\n",
      "usa-today_2016-10-26_clinton-walks-a-fine-line-betwee.txt\r\n",
      "usa-today_2016-10-26_congress-could-never-control-pre.txt\r\n",
      "usa-today_2016-10-26_wall-street-lawyers-dominate-cli.txt\r\n",
      "usa-today_2016-10-31_feds-in-talks-to-get-emails-from.txt\r\n",
      "usa-today_2016-11-02_keep-the-candidates-honest-by-al.txt\r\n",
      "usa-today_2016-11-07_step-plan-to-cope-if-your-candid.txt\r\n",
      "wash-post_2016-10-08_u-s-adds-jobs-unemployment-rate-.txt\r\n",
      "wash-post_2016-10-09_as-pyongyang-races-to-nuclear-go.txt\r\n",
      "wash-post_2016-10-09_u-s-officially-condemns-russia-o.txt\r\n",
      "wash-post_2016-10-10_scorched-earth-upends-a-usually-.txt\r\n",
      "wash-post_2016-10-15_sen-warren-asks-obama-to-fire-se.txt\r\n",
      "wash-post_2016-10-19_so-guess-who-s-the-demogorgon-in.txt\r\n",
      "wash-post_2016-10-24_clinton-embraced-big-money-syste.txt\r\n",
      "wash-post_2016-10-25_on-campus-trump-backers-have-lea.txt\r\n",
      "wash-post_2016-10-27_top-aide-s-leaked-memo-details-b.txt\r\n",
      "wash-post_2016-10-27_trump-leaves-campaign-trail-to-o.txt\r\n",
      "wash-post_2016-10-29_gop-places-heavy-bet-on-last-min.txt\r\n",
      "wash-post_2016-11-05_as-paris-climate-pact-takes-effe.txt\r\n",
      "west-journal_2016-10-11_donald-trump-claims-the-shackles.txt\r\n",
      "west-journal_2016-10-11_first-poll-released-since-second.txt\r\n",
      "west-journal_2016-10-14_lewinsky-reporter-reveals-that-o.txt\r\n",
      "west-journal_2016-10-14_witness-debunks-claim-trump-grop.txt\r\n",
      "west-journal_2016-10-17_polls-show-despite-campaign-of-a.txt\r\n",
      "west-journal_2016-10-19_lone-player-stands-during-nation.txt\r\n",
      "west-journal_2016-10-19_wikileaks-shows-desperate-plea-f.txt\r\n",
      "west-journal_2016-10-25_michael-moore-has-a-new-two-word.txt\r\n",
      "west-journal_2016-10-25_wikileaks-podesta-said-obamas-do.txt\r\n",
      "west-journal_2016-10-27_daughter-of-eric-garner-blasts-c.txt\r\n",
      "west-journal_2016-11-01_wikileaks-bombshell-podesta-inst.txt\r\n",
      "west-journal_2016-11-05_woman-who-accused-trump-of-rape-.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls ../data/academic-datasets/PolNeAR/data/test/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Attribution:T80 Cue:T79 Source:T78 Content:T77'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_file.loc[98][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>f_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>T80</td>\n",
       "      <td>Attribution 5896 5900</td>\n",
       "      <td>said</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>T79</td>\n",
       "      <td>Cue 5896 5900</td>\n",
       "      <td>said</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>T78</td>\n",
       "      <td>Source 5892 5895</td>\n",
       "      <td>she</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>T77</td>\n",
       "      <td>Content 5851 5891;5902 6000</td>\n",
       "      <td>“Africa might be luckier going forward,” “Here...</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                            1  \\\n",
       "97  T80        Attribution 5896 5900   \n",
       "96  T79                Cue 5896 5900   \n",
       "95  T78             Source 5892 5895   \n",
       "94  T77  Content 5851 5891;5902 6000   \n",
       "\n",
       "                                                    2  \\\n",
       "97                                               said   \n",
       "96                                               said   \n",
       "95                                                she   \n",
       "94  “Africa might be luckier going forward,” “Here...   \n",
       "\n",
       "                                                 f_id  \n",
       "97  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "96  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "95  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "94  ../data/academic-datasets/PolNeAR/data/annotat...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_file.loc[[97, 96, 95, 94]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = '../data/academic-datasets/PolNeAR/data/annotator-training/text/breitbart_2016-03-11_africa-builds-expertise-in-scien.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_file) as f:\n",
    "    text_file = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Africa might be luckier going forward,” she said. “Here we have to discuss and address deep, serious social challenges, and from there we can leap.”'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file[5851:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations_df = pd.concat(all_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    145003\n",
       "True          3\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_annotations_df[1].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "said                                            6142\n",
       "says                                             802\n",
       "told                                             527\n",
       "according to                                     410\n",
       "say                                              377\n",
       "                                                ... \n",
       "to show off later on their Instagram account       1\n",
       "depicting                                          1\n",
       "soon recalibrated                                  1\n",
       "scoffed                                            1\n",
       "tries to                                           1\n",
       "Name: 2, Length: 9641, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_annotations_df\n",
    " .loc[lambda df: df[0].str.contains('T')]\n",
    " .loc[lambda df: df[1].str.contains('Cue') == True][2]\n",
    " .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "polnear_sources = (\n",
    "    all_annotations_df\n",
    "     .loc[lambda df: df[0].str.contains('T')]\n",
    "     .loc[lambda df: df[1].str.contains('Source') == True][2]\n",
    "     .str.lower()\n",
    "     .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: any(map(lambda y: y in x, desired_checklist_of_anonymous_sources)), polnear_sources.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: any(map(lambda y: y in x and 'clinton' not in x, desired_checklist_of_documents)), polnear_sources.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "also told         9\n",
       "has announced     9\n",
       "also noted        9\n",
       "attacks on        9\n",
       "put it            9\n",
       "agree with        9\n",
       "calling for       9\n",
       "to discuss        9\n",
       "have shown        9\n",
       "went on to say    8\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_annotations_df\n",
    " .loc[lambda df: df[1].str.contains('Cue') == True].dropna()[2]\n",
    " .loc[lambda s: s.str.split().str.len() > 1]\n",
    " .str.lower()\n",
    " .loc[lambda s: ~s.str.contains('said')]\n",
    " .value_counts()\n",
    " .iloc[40:50]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_word_cues = (\n",
    "    all_annotations_df\n",
    "     .loc[lambda df: df[1].str.contains('Cue') == True].dropna()[2]\n",
    "     .loc[lambda s: s.str.split().str.len() == 1]\n",
    "     .str.lower()\n",
    "     .value_counts()\n",
    "     .index.tolist()[:500]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "pyperclip.copy(',\\n'.join(sorted(list(map(lambda x: '\"%s\"' % x, one_word_cues)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>f_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>Source 352 362</td>\n",
       "      <td>their club</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/test/at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>Cue 363 386</td>\n",
       "      <td>should publicly support</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/test/at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>Content 387 399</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/test/at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>Attribution 363 386</td>\n",
       "      <td>should publicly support</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/test/at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E1</td>\n",
       "      <td>Attribution:T4 Content:T3 Cue:T2 Source:T1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/test/at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>T77</td>\n",
       "      <td>Content 5851 5891;5902 6000</td>\n",
       "      <td>“Africa might be luckier going forward,” “Here...</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>T78</td>\n",
       "      <td>Source 5892 5895</td>\n",
       "      <td>she</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>T79</td>\n",
       "      <td>Cue 5896 5900</td>\n",
       "      <td>said</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>T80</td>\n",
       "      <td>Attribution 5896 5900</td>\n",
       "      <td>said</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>E19</td>\n",
       "      <td>Attribution:T80 Cue:T79 Source:T78 Content:T77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145006 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                               1  \\\n",
       "0    T1                                  Source 352 362   \n",
       "1    T2                                     Cue 363 386   \n",
       "2    T3                                 Content 387 399   \n",
       "3    T4                             Attribution 363 386   \n",
       "4    E1      Attribution:T4 Content:T3 Cue:T2 Source:T1   \n",
       "..  ...                                             ...   \n",
       "94  T77                     Content 5851 5891;5902 6000   \n",
       "95  T78                                Source 5892 5895   \n",
       "96  T79                                   Cue 5896 5900   \n",
       "97  T80                           Attribution 5896 5900   \n",
       "98  E19  Attribution:T80 Cue:T79 Source:T78 Content:T77   \n",
       "\n",
       "                                                    2  \\\n",
       "0                                          their club   \n",
       "1                             should publicly support   \n",
       "2                                        Donald Trump   \n",
       "3                             should publicly support   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "94  “Africa might be luckier going forward,” “Here...   \n",
       "95                                                she   \n",
       "96                                               said   \n",
       "97                                               said   \n",
       "98                                                NaN   \n",
       "\n",
       "                                                 f_id  \n",
       "0   ../data/academic-datasets/PolNeAR/data/test/at...  \n",
       "1   ../data/academic-datasets/PolNeAR/data/test/at...  \n",
       "2   ../data/academic-datasets/PolNeAR/data/test/at...  \n",
       "3   ../data/academic-datasets/PolNeAR/data/test/at...  \n",
       "4   ../data/academic-datasets/PolNeAR/data/test/at...  \n",
       "..                                                ...  \n",
       "94  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "95  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "96  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "97  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "98  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "\n",
       "[145006 rows x 4 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
