{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PolNeAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "import pandas as pd \n",
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import ast\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def get_loc_in_sent(char_idx, sent_lens_cumsum):\n",
    "    if not isinstance(char_idx, int):\n",
    "        char_idx = int(char_idx)\n",
    "    \n",
    "    sent_bin = np.digitize(char_idx, sent_len_cumsum)\n",
    "    offset_in_sent = char_idx - sent_len_cumsum[sent_bin - 1]\n",
    "    return sent_bin, offset_in_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = glob.glob('../data/academic-datasets/PolNeAR/data/*/text/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43843cac17334bb99ce8d941d5308df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_text = []\n",
    "all_annotations = []\n",
    "all_sentences = []\n",
    "for text_file in tqdm(text_files):\n",
    "    base_dir, filename = text_file.split('text/')\n",
    "    base_filename = filename.replace('.txt', '')\n",
    "    \n",
    "    ## read text\n",
    "    with open(text_file) as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        sents = list(doc.sents)\n",
    "        text_sents = list(map(str, sents))\n",
    "        sent_len_cumsum = list(map(lambda x: x.end_char, sents))\n",
    "        all_text.append({\n",
    "            'text_id': base_filename,\n",
    "            'text': text,\n",
    "            'sentences': text_sents\n",
    "        })\n",
    "        \n",
    "    ## read annotation\n",
    "    attr_dir = os.path.join(base_dir, 'attributions', '*')\n",
    "    annot_files = list(filter(lambda x: base_filename in x, glob.glob(attr_dir)))\n",
    "    for a in annot_files:\n",
    "        f_id = a.split('/')[-1]        \n",
    "        d = open(a).read()\n",
    "        t = list(map(lambda x: x.split('\\t'), d.split('\\n')))\n",
    "        t = list(filter(lambda x: len(x) > 1, t))\n",
    "        annotated_file = pd.DataFrame(t)\n",
    "\n",
    "        if len(annotated_file) == 0:\n",
    "            continue\n",
    "\n",
    "        annotated_file['source'] = np.nan\n",
    "        annotated_file['start_sentence'] = np.nan\n",
    "        annotated_file['end_sentence'] = np.nan\n",
    "\n",
    "        for row_idx, annotated_id, info_block in (\n",
    "            annotated_file\n",
    "                 .loc[lambda df: df[0].str.contains('T') == True]\n",
    "                 [[0, 1]].itertuples()\n",
    "        ):\n",
    "            chunks = info_block.split(' ')\n",
    "            block_type, char_idx_chunks = chunks[0], ' '.join(chunks[1:])\n",
    "            start_idxs, end_idxs = [], []\n",
    "            \n",
    "            for start_end_chunk in char_idx_chunks.split(';'):\n",
    "                start, end = start_end_chunk.split(' ')\n",
    "                start_sent_idx, char_start = get_loc_in_sent(start, sent_len_cumsum)\n",
    "                end_sent_idx, char_end = get_loc_in_sent(int(end) - 1, sent_len_cumsum)\n",
    "                start_idxs.append(start_sent_idx)\n",
    "                end_idxs.append(end_sent_idx)\n",
    "                \n",
    "            annotated_file.loc[row_idx, 'start_sentence'] = str(start_idxs)\n",
    "            annotated_file.loc[row_idx, 'end_sentence'] = str(end_idxs)\n",
    "\n",
    "        entities = annotated_file.loc[lambda df: df[0].str.contains('E')]\n",
    "        for source_block in entities[1]:\n",
    "            chunks = source_block.strip().split(' ')\n",
    "            ids = list(map(lambda x: x.split(':')[1], chunks))\n",
    "            source_ids = list(filter(lambda x: 'Source' in x, chunks ))\n",
    "            if len(source_ids) == 1:\n",
    "                source_id = source_ids[0].split(':')[1]\n",
    "                source_name = annotated_file.loc[lambda df: df[0] == source_id][2].iloc[0]\n",
    "                annotated_file.loc[lambda df: df[0].isin(ids), 'source'] = source_name \n",
    "            \n",
    "        annotated_file['t_id'] = base_filename\n",
    "        annotated_file['a_id'] = f_id\n",
    "        all_annotations.append(annotated_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations_df = pd.concat(all_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_df = (\n",
    "    pd.DataFrame(all_text)\n",
    "    .assign(sentences=lambda df: df['sentences'].apply(lambda x: list(map(lambda y: y.strip(), x))))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_annotations = (\n",
    "    all_annotations_df\n",
    "     .loc[lambda df: df['source'].notnull()]\n",
    "     .assign(start_sentence=lambda df: df['start_sentence'].apply(ast.literal_eval))\n",
    "     .assign(end_sentence=lambda df: df['end_sentence'].apply(ast.literal_eval))    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     96531\n",
       "2      3277\n",
       "3       132\n",
       "4        50\n",
       "6        12\n",
       "5        12\n",
       "7         2\n",
       "11        2\n",
       "20        1\n",
       "9         1\n",
       "10        1\n",
       "12        1\n",
       "8         1\n",
       "Name: start_sentence, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_annotations['start_sentence'].str.len().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentence_mapping = (\n",
    "    source_annotations\n",
    "     .groupby(['t_id', 'a_id', 'source'])\n",
    "     [['start_sentence', 'end_sentence']]\n",
    "     .aggregate(list)\n",
    "     .applymap(lambda x: list(set([s for l in x for s in l])))\n",
    "     .apply(lambda x: list(set(x['start_sentence'] + x['end_sentence'])), axis=1)\n",
    "     .to_frame('source_sentences')\n",
    "     .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionable_words = [\n",
    "#     'it',\n",
    "#     'which',\n",
    "#     'that',\n",
    "#     'some',\n",
    "#     'you',\n",
    "#     'many'\n",
    "]\n",
    "\n",
    "anonymous_sources = ['some', 'many']\n",
    "messy_sources = ['you', 'that', 'which', 'i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## check questionable sources\n",
    "if False:\n",
    "    t = (source_sentence_mapping\n",
    "             .loc[lambda df: df['source'].isin(questionable_words)]\n",
    "             .merge(all_text_df[['text_id', 'sentences']], left_on='t_id', right_on='text_id')\n",
    "             .assign(source_sentences_text=lambda df: \n",
    "                 df.apply(lambda x: list(map(lambda y: x['sentences'][y], x['source_sentences'])) , axis=1)\n",
    "            )\n",
    "    )\n",
    "\n",
    "    t[['source', 'source_sentences_text']].iloc[3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentence_mapping = source_sentence_mapping.loc[lambda df: ~df['source'].str.lower().isin(messy_sources)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_sentence_lists = (\n",
    "    source_sentence_mapping\n",
    "     .groupby('t_id')[['source', 'source_sentences']]\n",
    "     .aggregate(list)\n",
    "     .assign(source=lambda df: df.apply(lambda x: [[x['source'][i]] * len(s) for i, s in enumerate(x['source_sentences'])], axis=1))\n",
    "     .applymap(lambda x: [s for l in x for s in l])\n",
    "#      .apply(lambda x: list(set(x)))\n",
    "#      .to_frame('quote_sentences')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_sentence_lists_exploded = (\n",
    "    quote_sentence_lists\n",
    "     .apply(lambda x: list(map(lambda y: {'source': y[0], 'sent': y[1], 't_id': x.name}, zip(x['source'], x['source_sentences']))) , axis=1)\n",
    "     .pipe(lambda s: pd.DataFrame([i for x in s for i in x]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_df_exploded = (all_text_df\n",
    " .apply(lambda x: list(map(lambda y: {'s': y[1], 's_idx': y[0], 't_id': x['text_id']}, enumerate(x['sentences']))), axis=1)\n",
    " .pipe(lambda s: pd.DataFrame([i for x in s for i in x]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_quotes_exploded = (\n",
    "    all_text_df_exploded\n",
    "     .merge(quote_sentence_lists_exploded, how='left', left_on=['t_id', 's_idx'], right_on=['t_id', 'sent'])\n",
    "     .set_index('t_id')\n",
    "     .drop(['sent', \n",
    "#             's_idx'\n",
    "           ], axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ids = (matched_quotes_exploded.index.unique().tolist())\n",
    "\n",
    "\n",
    "t_ids = (\n",
    "    matched_quotes_exploded\n",
    "     .loc[lambda df: df['source'].notnull()]\n",
    "     .loc[lambda df: df.apply(lambda x: x['source'] not in x['s'], axis=1)]\n",
    "     .index.unique().tolist() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreferent_sources = ['he', 'she', 'who', 'they', 'her', 'his', 'a', 'some', 'q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ids = (matched_quotes_exploded\n",
    " .loc[lambda df: ~df['source'].str.lower().isin(coreferent_sources)]\n",
    " # source not in the sentence\n",
    " .loc[lambda df: df['source'].notnull()]\n",
    " .loc[lambda df: df.apply(lambda x: x['source'] not in x['s'], axis=1)] \n",
    " .reset_index()\n",
    " .assign(c=1)\n",
    " .groupby(['t_id', 'source'])\n",
    " ['c'].sum()\n",
    " .reset_index()\n",
    " .loc[lambda df: df['c'] > 1]\n",
    " ['t_id'].unique().tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5\n",
    "d = matched_quotes_exploded.loc[t_ids[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_all = '<table>'\n",
    "for sent, s_idx, source in d.itertuples(index=False):\n",
    "    if pd.notnull(source):\n",
    "        html_all += '<tr><td style=\"background-color: pink\">' +  sent + '</td><td>' + source + '</tr>'\n",
    "    else:\n",
    "        html_all += '<tr><td>' + sent + '</td><td></td></tr>'\n",
    "html_all += '</table>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Exclusive–Maria Espinoza, Anti-Illegal-Immigration Leader, Running For Congress.</td><td></td></tr><tr><td>Anti-illegal immigration leader Maria Espinoza is running for Congress in the 7th congressional district in Texas.</td><td></td></tr><tr><td style=\"background-color: pink\">Espinoza is Co-founder and National Director of The Remembrance Project, a non-profit that advocates for families of Americans who have been killed by illegal aliens.</td><td>a non-profit</tr><tr><td style=\"background-color: pink\">She will be challenging incumbent Rep. John Culberson (R-TX).</td><td>She</tr><tr><td style=\"background-color: pink\">“Culberson just isn’t working any more.</td><td>Espinoza</tr><tr><td style=\"background-color: pink\">In fact, last year, he missed the second most votes of any Texas Congressman and was among the bottom ten percent of all members of Congress for missed votes,” Espinoza tells Breitbart News.</td><td>Espinoza</tr><tr><td style=\"background-color: pink\">“Culberson is now part of the problem in Washington, not the solution,” Espinoza said.</td><td>Espinoza</tr><tr><td style=\"background-color: pink\">“Fourteen years in Congress is long enough.</td><td>Espinoza</tr><tr><td style=\"background-color: pink\">Conservatives can no longer count on Culberson.”</td><td>Espinoza</tr><tr><td>Espinoza is of Mexican descent and is a sixth generation Texan from her mother’s side.</td><td></td></tr><tr><td style=\"background-color: pink\">She recently praised Republican presidential candidate Donald Trump for speaking out against illegal aliens.</td><td>She</tr><tr><td>In August Trump met with Espinoza and families of victims killed by illegal aliens.</td><td></td></tr><tr><td style=\"background-color: pink\">“I won’t just talk like a conservative during the election season,” Espinoza said Friday.</td><td>Espinoza</tr><tr><td style=\"background-color: pink\">\"I am a proven champion for Constitutional governance, individual liberty and the Rule of Law.</td><td>Espinoza</tr><tr><td style=\"background-color: pink\">I have boldly faced down attacks from the Liberal Left, and even Establishment figures in my own party, to speak the truth about the crises facing our country, especially on the issues of border security and immigration.\"</td><td>Espinoza</tr><tr><td style=\"background-color: pink\">“I will take that same strength of conviction to Washington, standing up for our conservative values and American families,” Espinoza said.</td><td>Espinoza</tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(matched_quotes_exploded.reset_index()['t_id'].drop_duplicates().tolist())\n",
    "train_test_info = pd.concat([\n",
    "    pd.Series(train).to_frame('files').assign(group='/train/'),\n",
    "    pd.Series(test).to_frame('files').assign(group='/test/')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "(matched_quotes_exploded\n",
    " .assign(source=lambda df: df['source'].isnull())\n",
    " .reset_index()\n",
    " .merge(train_test_info, left_on='t_id', right_on='files', how='left')\n",
    " .assign(t_id=lambda df: df['group'] + df['t_id'])\n",
    " .groupby(['t_id', 's', 's_idx'])['source'].any()\n",
    " .reset_index()\n",
    " .sort_values(['t_id', 's_idx'])\n",
    " [['source', 's', 't_id', 's_idx'] ]\n",
    "  .to_csv('../models/neural_models/quote_detection/data/polnear-training-data-stage-1.tsv', index=False, sep='\\t')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'notebook'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook.__package__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Author Roger Stone',\n",
       " 'Breitbart Jerusalem editor Aaron Klein',\n",
       " 'Breitbart London’s Raheem Kassam',\n",
       " 'Breitbart Texas editor Brandon Darby',\n",
       " 'Dave Gorab',\n",
       " 'Investigative reporter\\xa0Julia Hahn',\n",
       " 'Pope Francis']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = (source_sentence_mapping\n",
    " .groupby(['t_id', 'a_id'])\n",
    " ['source'].aggregate(list).iloc[6]\n",
    ")\n",
    "\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'Former Secretary of State and Democratic presidential frontrunner Hillary Clinton'\n",
    "t = 'Author Roger Stone'\n",
    "t = t3[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = list(nlp(t).ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Breitbart London’s, Raheem Kassam]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = ents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PERSON'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PERSON', 'PERSON']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x.label_, ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>source</th>\n",
       "      <th>source_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wash-post_2016-10-19_so-guess-who-s-the-demogo...</td>\n",
       "      <td>So guess who's the Demogorgon in this scenario...</td>\n",
       "      <td>[So guess who's the Demogorgon in this scenari...</td>\n",
       "      <td>[Clinton, He, His office, Liberals, Newt Gingr...</td>\n",
       "      <td>[32, 35, 10, 41, 15, 9, 38, 7, 28, 36, 32, 33,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breitbart_2016-11-02_asian-markets-on-edge-on-...</td>\n",
       "      <td>Asian markets on edge on US election uncertain...</td>\n",
       "      <td>[Asian markets on edge on US election uncertai...</td>\n",
       "      <td>[Chris Weston, chief market strategist in Melb...</td>\n",
       "      <td>[5, 6, 7, 19, 4, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>west-journal_2016-10-11_donald-trump-claims-th...</td>\n",
       "      <td>Donald Trump Claims ‘The Shackles’ Have Now Be...</td>\n",
       "      <td>[Donald Trump Claims ‘The Shackles’ Have Now B...</td>\n",
       "      <td>[Donald Trump, House Speaker Paul Ryan, Joshua...</td>\n",
       "      <td>[0, 5, 17, 18, 16, 1, 8, 9, 15, 11, 4, 6, 10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usa-today_2016-10-26_congress-could-never-cont...</td>\n",
       "      <td>Congress could never control President Trump.\\...</td>\n",
       "      <td>[Congress could never control President Trump....</td>\n",
       "      <td>[An unusual number of Republican lawmakers, Co...</td>\n",
       "      <td>[4, 24, 1, 10, 29, 11, 15, 25, 10, 27, 20, 16,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>west-journal_2016-10-19_lone-player-stands-dur...</td>\n",
       "      <td>Lone Player Stands During National Anthem Whil...</td>\n",
       "      <td>[Lone Player Stands During National Anthem, Wh...</td>\n",
       "      <td>[Brewer, Jewell Young, a Decatur resident, Jew...</td>\n",
       "      <td>[6, 20, 21, 22, 14, 12, 26, 29, 11, 23, 19, 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>politico_2016-09-30_flight-attendants-union-en...</td>\n",
       "      <td>Flight attendants' union endorses Clinton.\\n\\n...</td>\n",
       "      <td>[Flight attendants' union endorses Clinton., A...</td>\n",
       "      <td>[A union representing flight attendants, Fligh...</td>\n",
       "      <td>[1, 0, 5, 3, 2, 6, 1, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>breitbart_2016-03-11_activists-who-lit-syria-r...</td>\n",
       "      <td>Activists who lit Syria revolt washed away in ...</td>\n",
       "      <td>[Activists who lit Syria revolt washed away in...</td>\n",
       "      <td>[He, He, He, Jimmy Shahinian, a 28-year-old ac...</td>\n",
       "      <td>[32, 26, 39, 3, 4, 33, 34, 35, 27, 28, 29, 22,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>breitbart_2016-03-11_africa-builds-expertise-i...</td>\n",
       "      <td>Africa builds expertise in science, tech, engi...</td>\n",
       "      <td>[Africa builds expertise in science, tech, eng...</td>\n",
       "      <td>[Alta Schutte, Gitau, Gitau, who specializes i...</td>\n",
       "      <td>[2, 43, 33, 32, 10, 17, 28, 44, 7, 13, 14, 36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>breitbart_2016-03-11_activists-brick-up-entran...</td>\n",
       "      <td>Activists Brick Up Entrance To Migrants-Only P...</td>\n",
       "      <td>[Activists Brick Up Entrance To Migrants-Only ...</td>\n",
       "      <td>[A source from the German Identitarian Movemen...</td>\n",
       "      <td>[18, 19, 22, 21, 23, 1, 7, 6, 8, 4, 24, 17, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>breitbart_2016-03-11_afghanistan-thrash-zimbab...</td>\n",
       "      <td>Afghanistan thrash Zimbabwe in World Twenty20....</td>\n",
       "      <td>[Afghanistan thrash Zimbabwe in World Twenty20...</td>\n",
       "      <td>[Nabi, The duo, Nabi, Nabi, Nabi, Nabi, Nabi, ...</td>\n",
       "      <td>[7, 6, 7, 7, 7, 7, 7, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text_id  \\\n",
       "0     wash-post_2016-10-19_so-guess-who-s-the-demogo...   \n",
       "1     breitbart_2016-11-02_asian-markets-on-edge-on-...   \n",
       "2     west-journal_2016-10-11_donald-trump-claims-th...   \n",
       "3     usa-today_2016-10-26_congress-could-never-cont...   \n",
       "4     west-journal_2016-10-19_lone-player-stands-dur...   \n",
       "...                                                 ...   \n",
       "1007  politico_2016-09-30_flight-attendants-union-en...   \n",
       "1008  breitbart_2016-03-11_activists-who-lit-syria-r...   \n",
       "1009  breitbart_2016-03-11_africa-builds-expertise-i...   \n",
       "1010  breitbart_2016-03-11_activists-brick-up-entran...   \n",
       "1011  breitbart_2016-03-11_afghanistan-thrash-zimbab...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     So guess who's the Demogorgon in this scenario...   \n",
       "1     Asian markets on edge on US election uncertain...   \n",
       "2     Donald Trump Claims ‘The Shackles’ Have Now Be...   \n",
       "3     Congress could never control President Trump.\\...   \n",
       "4     Lone Player Stands During National Anthem Whil...   \n",
       "...                                                 ...   \n",
       "1007  Flight attendants' union endorses Clinton.\\n\\n...   \n",
       "1008  Activists who lit Syria revolt washed away in ...   \n",
       "1009  Africa builds expertise in science, tech, engi...   \n",
       "1010  Activists Brick Up Entrance To Migrants-Only P...   \n",
       "1011  Afghanistan thrash Zimbabwe in World Twenty20....   \n",
       "\n",
       "                                              sentences  \\\n",
       "0     [So guess who's the Demogorgon in this scenari...   \n",
       "1     [Asian markets on edge on US election uncertai...   \n",
       "2     [Donald Trump Claims ‘The Shackles’ Have Now B...   \n",
       "3     [Congress could never control President Trump....   \n",
       "4     [Lone Player Stands During National Anthem, Wh...   \n",
       "...                                                 ...   \n",
       "1007  [Flight attendants' union endorses Clinton., A...   \n",
       "1008  [Activists who lit Syria revolt washed away in...   \n",
       "1009  [Africa builds expertise in science, tech, eng...   \n",
       "1010  [Activists Brick Up Entrance To Migrants-Only ...   \n",
       "1011  [Afghanistan thrash Zimbabwe in World Twenty20...   \n",
       "\n",
       "                                                 source  \\\n",
       "0     [Clinton, He, His office, Liberals, Newt Gingr...   \n",
       "1     [Chris Weston, chief market strategist in Melb...   \n",
       "2     [Donald Trump, House Speaker Paul Ryan, Joshua...   \n",
       "3     [An unusual number of Republican lawmakers, Co...   \n",
       "4     [Brewer, Jewell Young, a Decatur resident, Jew...   \n",
       "...                                                 ...   \n",
       "1007  [A union representing flight attendants, Fligh...   \n",
       "1008  [He, He, He, Jimmy Shahinian, a 28-year-old ac...   \n",
       "1009  [Alta Schutte, Gitau, Gitau, who specializes i...   \n",
       "1010  [A source from the German Identitarian Movemen...   \n",
       "1011  [Nabi, The duo, Nabi, Nabi, Nabi, Nabi, Nabi, ...   \n",
       "\n",
       "                                       source_sentences  \n",
       "0     [32, 35, 10, 41, 15, 9, 38, 7, 28, 36, 32, 33,...  \n",
       "1                                  [5, 6, 7, 19, 4, 18]  \n",
       "2     [0, 5, 17, 18, 16, 1, 8, 9, 15, 11, 4, 6, 10, ...  \n",
       "3     [4, 24, 1, 10, 29, 11, 15, 25, 10, 27, 20, 16,...  \n",
       "4     [6, 20, 21, 22, 14, 12, 26, 29, 11, 23, 19, 24...  \n",
       "...                                                 ...  \n",
       "1007                        [1, 0, 5, 3, 2, 6, 1, 2, 3]  \n",
       "1008  [32, 26, 39, 3, 4, 33, 34, 35, 27, 28, 29, 22,...  \n",
       "1009  [2, 43, 33, 32, 10, 17, 28, 44, 7, 13, 14, 36,...  \n",
       "1010  [18, 19, 22, 21, 23, 1, 7, 6, 8, 4, 24, 17, 15...  \n",
       "1011                           [7, 6, 7, 7, 7, 7, 7, 6]  \n",
       "\n",
       "[1008 rows x 5 columns]"
      ]
     },
     "execution_count": 986,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = all_text_df.merge(quote_sentence_lists, right_index=True, left_on='text_id')\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuoBERT Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotbert_annotated_data = pd.read_json('../models_other/Quotebank/quobert/annotated_mturk.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_quote        210\n",
       "none             201\n",
       "not_mentioned    159\n",
       "ambiguous         42\n",
       "other            888\n",
       "dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    quotbert_annotated_data['speaker']\n",
    "     .value_counts()\n",
    "     .pipe(lambda s: pd.concat([s[:4], pd.Series({'other': s[4:].sum()})]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'articleUID': '2015121004_00119255_W',\n",
       " 'articleOffset': 0,\n",
       " 'leftContext': '. The Council has extended the deadline for further submissions from the original closing date of next Wednesday until the end of next week, Friday 18 December. Tony Avery, the Interim General Manager of Planning and Development, said that the decision had been made in light of the large number of original submissions, and the short 10 day time frame specified in the Resource Management Act for making further submissions.',\n",
       " 'quotation': 'This will assist people in digesting the large number of rezoning requests, which took longer than expected to map accurately, and which are now easily viewable online.',\n",
       " 'rightContext': \"Mr Avery also cautioned that while the map was a helpful tool, anyone interested in making a further submission should always refer back to the original submission. The map, the submissions and a summary are all on the Council's website www.qldc.govt.nz\",\n",
       " 'speaker': 'Tony Avery',\n",
       " 'entities': \"['Tony Avery']\",\n",
       " 'results': \"[('0', 3)]\",\n",
       " 'none_reason': '',\n",
       " 'other_reason': ''}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotbert_annotated_data.loc[4].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.txt  test.csv    train.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls ../data/academic-datasets/IBMDebaterEvidenceSentences/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_evidence = pd.read_csv('../data/academic-datasets/wikipedia_evidence_dataset_29429.csv')\n",
    "ibm_debater_evidence_sentences = pd.read_csv('../data/academic-datasets/IBMDebaterEvidenceSentences/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In 2001 and 2002 Simeoni was suspended for several months for doping use.'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_evidence['Evidence'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'We should limit executive compensation',\n",
       " 'the concept of the topic': 'executive compensation',\n",
       " 'candidate': 'In 2007, the Chairman of the Financial Services Committee Rep. Barney Frank passed legislation in the House of Representatives that gave shareholders a non-binding vote on executive compensation.',\n",
       " 'candidate masked': 'In 2007, the Chairman of the Financial Services Committee Rep. Barney Frank passed legislation in the House of Representatives that gave shareholders a non-binding vote on TOPIC_CONCEPT.',\n",
       " 'label': 0,\n",
       " 'wikipedia article name': 'Say on pay',\n",
       " 'wikipedia url': 'https://en.wikipedia.org/wiki/Say_on_pay'}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibm_debater_evidence_sentences.iloc[5].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'We should ban partial birth abortions',\n",
       " 'candidate': 'Kennedy\\'s majority opinion argued that the case differed from Stenberg v. Carhart, a 2000 case in which the Supreme Court struck down a state ban on \"partial-birth abortion\" as unconstitutional, in that the Partial Birth Abortion Act defined the banned procedure more clearly.',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ibm_debater_evidence_sentences\n",
    " .loc[lambda df: df['label'] == 1]\n",
    " [['topic', 'candidate', 'label']]\n",
    " .iloc[15]\n",
    " .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'We should limit executive compensation',\n",
       " 'candidate': 'In 2005, Goodwill Industries of the Columbia Willamette (GICW), Goodwill\\'s Portland, Oregon branch, came under scrutiny due to executive compensation that the Oregon attorney general\\'s office concluded was \"unreasonable.\"',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ibm_debater_evidence_sentences\n",
    " .loc[lambda df: df['label'] == 0]\n",
    " [['topic', 'candidate', 'label']]\n",
    " .iloc[8]\n",
    " .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Attribution:T80 Cue:T79 Source:T78 Content:T77'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_file.loc[98][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>f_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>T80</td>\n",
       "      <td>Attribution 5896 5900</td>\n",
       "      <td>said</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>T79</td>\n",
       "      <td>Cue 5896 5900</td>\n",
       "      <td>said</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>T78</td>\n",
       "      <td>Source 5892 5895</td>\n",
       "      <td>she</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>T77</td>\n",
       "      <td>Content 5851 5891;5902 6000</td>\n",
       "      <td>“Africa might be luckier going forward,” “Here...</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                            1  \\\n",
       "97  T80        Attribution 5896 5900   \n",
       "96  T79                Cue 5896 5900   \n",
       "95  T78             Source 5892 5895   \n",
       "94  T77  Content 5851 5891;5902 6000   \n",
       "\n",
       "                                                    2  \\\n",
       "97                                               said   \n",
       "96                                               said   \n",
       "95                                                she   \n",
       "94  “Africa might be luckier going forward,” “Here...   \n",
       "\n",
       "                                                 f_id  \n",
       "97  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "96  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "95  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "94  ../data/academic-datasets/PolNeAR/data/annotat...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_file.loc[[97, 96, 95, 94]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = '../data/academic-datasets/PolNeAR/data/annotator-training/text/breitbart_2016-03-11_africa-builds-expertise-in-scien.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_file) as f:\n",
    "    text_file = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Africa might be luckier going forward,” she said. “Here we have to discuss and address deep, serious social challenges, and from there we can leap.”'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file[5851:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations_df = pd.concat(all_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    145003\n",
       "True          3\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_annotations_df[1].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "said                                            6142\n",
       "says                                             802\n",
       "told                                             527\n",
       "according to                                     410\n",
       "say                                              377\n",
       "                                                ... \n",
       "to show off later on their Instagram account       1\n",
       "depicting                                          1\n",
       "soon recalibrated                                  1\n",
       "scoffed                                            1\n",
       "tries to                                           1\n",
       "Name: 2, Length: 9641, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_annotations_df\n",
    " .loc[lambda df: df[0].str.contains('T')]\n",
    " .loc[lambda df: df[1].str.contains('Cue') == True][2]\n",
    " .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "polnear_sources = (\n",
    "    all_annotations_df\n",
    "     .loc[lambda df: df[0].str.contains('T')]\n",
    "     .loc[lambda df: df[1].str.contains('Source') == True][2]\n",
    "     .str.lower()\n",
    "     .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: any(map(lambda y: y in x, desired_checklist_of_anonymous_sources)), polnear_sources.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: any(map(lambda y: y in x and 'clinton' not in x, desired_checklist_of_documents)), polnear_sources.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "also told         9\n",
       "has announced     9\n",
       "also noted        9\n",
       "attacks on        9\n",
       "put it            9\n",
       "agree with        9\n",
       "calling for       9\n",
       "to discuss        9\n",
       "have shown        9\n",
       "went on to say    8\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_annotations_df\n",
    " .loc[lambda df: df[1].str.contains('Cue') == True].dropna()[2]\n",
    " .loc[lambda s: s.str.split().str.len() > 1]\n",
    " .str.lower()\n",
    " .loc[lambda s: ~s.str.contains('said')]\n",
    " .value_counts()\n",
    " .iloc[40:50]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_word_cues = (\n",
    "    all_annotations_df\n",
    "     .loc[lambda df: df[1].str.contains('Cue') == True].dropna()[2]\n",
    "     .loc[lambda s: s.str.split().str.len() == 1]\n",
    "     .str.lower()\n",
    "     .value_counts()\n",
    "     .index.tolist()[:500]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "pyperclip.copy(',\\n'.join(sorted(list(map(lambda x: '\"%s\"' % x, one_word_cues)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>f_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>Source 352 362</td>\n",
       "      <td>their club</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/test/at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>Cue 363 386</td>\n",
       "      <td>should publicly support</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/test/at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>Content 387 399</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/test/at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>Attribution 363 386</td>\n",
       "      <td>should publicly support</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/test/at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E1</td>\n",
       "      <td>Attribution:T4 Content:T3 Cue:T2 Source:T1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/test/at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>T77</td>\n",
       "      <td>Content 5851 5891;5902 6000</td>\n",
       "      <td>“Africa might be luckier going forward,” “Here...</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>T78</td>\n",
       "      <td>Source 5892 5895</td>\n",
       "      <td>she</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>T79</td>\n",
       "      <td>Cue 5896 5900</td>\n",
       "      <td>said</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>T80</td>\n",
       "      <td>Attribution 5896 5900</td>\n",
       "      <td>said</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>E19</td>\n",
       "      <td>Attribution:T80 Cue:T79 Source:T78 Content:T77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/academic-datasets/PolNeAR/data/annotat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145006 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                               1  \\\n",
       "0    T1                                  Source 352 362   \n",
       "1    T2                                     Cue 363 386   \n",
       "2    T3                                 Content 387 399   \n",
       "3    T4                             Attribution 363 386   \n",
       "4    E1      Attribution:T4 Content:T3 Cue:T2 Source:T1   \n",
       "..  ...                                             ...   \n",
       "94  T77                     Content 5851 5891;5902 6000   \n",
       "95  T78                                Source 5892 5895   \n",
       "96  T79                                   Cue 5896 5900   \n",
       "97  T80                           Attribution 5896 5900   \n",
       "98  E19  Attribution:T80 Cue:T79 Source:T78 Content:T77   \n",
       "\n",
       "                                                    2  \\\n",
       "0                                          their club   \n",
       "1                             should publicly support   \n",
       "2                                        Donald Trump   \n",
       "3                             should publicly support   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "94  “Africa might be luckier going forward,” “Here...   \n",
       "95                                                she   \n",
       "96                                               said   \n",
       "97                                               said   \n",
       "98                                                NaN   \n",
       "\n",
       "                                                 f_id  \n",
       "0   ../data/academic-datasets/PolNeAR/data/test/at...  \n",
       "1   ../data/academic-datasets/PolNeAR/data/test/at...  \n",
       "2   ../data/academic-datasets/PolNeAR/data/test/at...  \n",
       "3   ../data/academic-datasets/PolNeAR/data/test/at...  \n",
       "4   ../data/academic-datasets/PolNeAR/data/test/at...  \n",
       "..                                                ...  \n",
       "94  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "95  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "96  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "97  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "98  ../data/academic-datasets/PolNeAR/data/annotat...  \n",
       "\n",
       "[145006 rows x 4 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
