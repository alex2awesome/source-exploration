{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8226fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/job/.local/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://artifactory.inf.bloomberg.com/artifactory/api/pypi/bloomberg-pypi/simple/, https://artifactory.inf.bloomberg.com/artifactory/api/pypi/python-dsp-wheels/simple\n",
      "Collecting attrdict\n",
      "  Downloading https://artifactory.inf.bloomberg.com/artifactory/api/pypi/bloomberg-pypi/packages/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: six in /job/.local/lib/python3.7/site-packages (from attrdict) (1.16.0)\n",
      "Installing collected packages: attrdict\n",
      "Successfully installed attrdict-2.0.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from models_neural.quote_attribution.classification_models import SourceQA, SourceClassifier\n",
    "import json\n",
    "try:\n",
    "    import attrdict\n",
    "except:\n",
    "    ! pip install attrdict\n",
    "    import attrdict\n",
    "from models_neural.src.config_helper import TransformersConfig\n",
    "import pandas as pd \n",
    "import zipfile\n",
    "from models_neural.quote_attribution.utils_dataset import SourceQADataModule, SourceClassificationDataModule\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94ec1a43-6096-406b-9fc6-f3ea9d4556f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aspangher/spacy/en_core_web_lg/meta.json to en_core_web_lg/meta.json   \n",
      "download: s3://aspangher/spacy/en_core_web_lg/accuracy.json to en_core_web_lg/accuracy.json\n",
      "download: s3://aspangher/spacy/en_core_web_lg/ner/cfg to en_core_web_lg/ner/cfg       \n",
      "download: s3://aspangher/spacy/en_core_web_lg/ner/moves to en_core_web_lg/ner/moves  \n",
      "download: s3://aspangher/spacy/en_core_web_lg/parser/moves to en_core_web_lg/parser/moves\n",
      "download: s3://aspangher/spacy/en_core_web_lg/parser/cfg to en_core_web_lg/parser/cfg\n",
      "download: s3://aspangher/spacy/en_core_web_lg/tagger/cfg to en_core_web_lg/tagger/cfg\n",
      "download: s3://aspangher/spacy/en_core_web_lg/tagger/tag_map to en_core_web_lg/tagger/tag_map\n",
      "download: s3://aspangher/spacy/en_core_web_lg/tokenizer to en_core_web_lg/tokenizer\n",
      "download: s3://aspangher/spacy/en_core_web_lg/vocab/lookups_extra.bin to en_core_web_lg/vocab/lookups_extra.bin\n",
      "download: s3://aspangher/spacy/en_core_web_lg/ner/model to en_core_web_lg/ner/model\n",
      "download: s3://aspangher/spacy/en_core_web_lg/vocab/lookups.bin to en_core_web_lg/vocab/lookups.bin\n",
      "download: s3://aspangher/spacy/en_core_web_lg/tagger/model to en_core_web_lg/tagger/model\n",
      "download: s3://aspangher/spacy/en_core_web_lg/parser/model to en_core_web_lg/parser/model\n",
      "download: s3://aspangher/spacy/en_core_web_lg/vocab/key2row to en_core_web_lg/vocab/key2row\n",
      "download: s3://aspangher/spacy/en_core_web_lg/vocab/strings.json to en_core_web_lg/vocab/strings.json\n",
      "download: s3://aspangher/spacy/en_core_web_lg/vocab/vectors to en_core_web_lg/vocab/vectors\n",
      "download: s3://aspangher/transformer-pretrained-models/roberta-base-expanded-embeddings.zip to ./roberta-base-expanded-embeddings.zip\n"
     ]
    }
   ],
   "source": [
    "remote = True\n",
    "if remote: \n",
    "    # download pretrained models/spacy \n",
    "    ! aws s3 cp --recursive s3://aspangher/spacy/en_core_web_lg/ en_core_web_lg/ --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "    ! aws s3 cp s3://aspangher/transformer-pretrained-models/roberta-base-expanded-embeddings.zip .  --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "    with zipfile.ZipFile('roberta-base-expanded-embeddings.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a747ea62-43da-4ba1-ab59-0d8ea5327644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aspangher/source-exploration/data/our-annotated-data__stage-2.tsv to ./our-annotated-data__stage-2.tsv\n"
     ]
    }
   ],
   "source": [
    "if remote:\n",
    "    ! aws s3 cp s3://aspangher/source-exploration/data/our-annotated-data__stage-2.tsv  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "    data_fn = 'our-annotated-data__stage-2.tsv'\n",
    "else:\n",
    "    data_fn = '../models_neural/quote_attribution/data/our-annotated-data__stage-2.tsv'\n",
    "data_df = pd.read_csv(data_fn, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939b7e79-244c-4680-9529-d4bed3f89957",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_trained_models = ! aws s3 ls s3://aspangher/source-exploration/./ --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "uploaded_trained_models = list(map(lambda x: ' '.join(x.split()[3:]), uploaded_trained_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ae69ec-33b5-4542-9de0-f908a3dbb794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config-Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. More unfrozen..json',\n",
       " 'config-Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. No train on None..json',\n",
       " 'config-Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only..json',\n",
       " 'config-Stage 2: Quote Attribution + Detection. Classification. Method 2. Sanity Check..json',\n",
       " 'config-Stage 2: Quote Attribution + Detection. Classification. Our dataset only..json',\n",
       " 'config-Stage 2: Quote Attribution + Detection. Classification. Token Expansion. Our full dataset only. No train on None..json',\n",
       " 'config-Stage 2: Quote Attribution + Detection. Classification. Token Expansion. Our full dataset only..json',\n",
       " 'config-Stage 2: Quote Attribution. Classification. Our dataset only..json',\n",
       " 'config-Stage 2: Quote Attribution. Our dataset only..json',\n",
       " 'trial-Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. More unfrozen.__epoch=06-perplexity=0.00.ckpt',\n",
       " 'trial-Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. No train on None.__epoch=09-perplexity=0.00.ckpt',\n",
       " 'trial-Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only.__epoch=08-perplexity=0.00.ckpt',\n",
       " 'trial-Stage 2: Quote Attribution + Detection. Classification. Method 2. Sanity Check.__epoch=09-perplexity=0.00.ckpt',\n",
       " 'trial-Stage 2: Quote Attribution + Detection. Classification. Our dataset only.__epoch=01-perplexity=0.00.ckpt',\n",
       " 'trial-Stage 2: Quote Attribution + Detection. Classification. Token Expansion. Our full dataset only. No train on None.__epoch=00-perplexity=0.00.ckpt',\n",
       " 'trial-Stage 2: Quote Attribution + Detection. Classification. Token Expansion. Our full dataset only.__epoch=08-perplexity=0.00.ckpt',\n",
       " 'trial-Stage 2: Quote Attribution. Classification. Our dataset only.__epoch=08-perplexity=0.00.ckpt',\n",
       " 'trial-Stage 2: Quote Attribution. Classification. Our dataset only.__epoch=09-perplexity=0.00.ckpt',\n",
       " 'trial-Stage 2: Quote Attribution. Our dataset only.__epoch=05-perplexity=0.00.ckpt',\n",
       " \"trial-Stage 2: Quote Detection + Attribution (i.e. train attribution on 'None'). Our dataset only.__epoch=07-perplexity=0.00.ckpt\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_trained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da62ad6-51da-48ce-9f99-0d6c49beb53f",
   "metadata": {},
   "source": [
    "# Sanity Check Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329fcb2e-f245-40eb-8e67-664a90e38ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aspangher/source-exploration/data/quote-attribution-classification__sanity-check-data.tsv to ./quote-attribution-classification__sanity-check-data.tsv\n"
     ]
    }
   ],
   "source": [
    "remote = True\n",
    "if remote:\n",
    "    ! aws s3 cp s3://aspangher/source-exploration/data/quote-attribution-classification__sanity-check-data.tsv  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "    data_fn = 'quote-attribution-classification__sanity-check-data.tsv'\n",
    "else:\n",
    "    data_fn = '../models_neural/quote_attribution/data/quote-attribution-classification__sanity-check-data.tsv'\n",
    "data_df = pd.read_csv(data_fn, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0185bec1-9934-4071-a61d-87ae8b703e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. No train on None'\n",
    "model_name = 'Sanity Check'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63ec9162-c2c3-4ec3-b945-c72525ba3702",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = list(filter(lambda x: model_name in x, uploaded_trained_models))\n",
    "model_path = list(filter(lambda x: 'trial-' in x, paths))[0]\n",
    "config_path = list(filter(lambda x: 'config-' in x, paths))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e758794-7ebc-403b-a671-94b941fd60b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aspangher/source-exploration/./config-Stage 2: Quote Attribution + Detection. Classification. Method 2. Sanity Check..json to ./config-Stage 2: Quote Attribution + Detection. Classification. Method 2. Sanity Check..json\n",
      "download: s3://aspangher/source-exploration/./trial-Stage 2: Quote Attribution + Detection. Classification. Method 2. Sanity Check.__epoch=09-perplexity=0.00.ckpt to ./trial-Stage 2: Quote Attribution + Detection. Classification. Method 2. Sanity Check.__epoch=09-perplexity=0.00.ckpt\n"
     ]
    }
   ],
   "source": [
    "paths = list(filter(lambda x: model_name in x, uploaded_trained_models))\n",
    "model_path = list(filter(lambda x: 'trial-' in x, paths))[0]\n",
    "config_path = list(filter(lambda x: 'config-' in x, paths))[0]\n",
    "if remote:\n",
    "    # download config\n",
    "    ! aws s3 cp \"s3://aspangher/source-exploration/./$config_path\"  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "                \n",
    "    # download models\n",
    "    ! aws s3 cp \"s3://aspangher/source-exploration/./$model_path\"  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "974b5a4e-5363-4b1c-8878-8d5839830bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_path) as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "config_dict = attrdict.AttrDict(config_dict)\n",
    "config_dict.pretrained_files_s3 = config_dict.pretrained_model_path\n",
    "config_dict.model_type = 'roberta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a269a9c-5bbd-4a76-bb03-1eaeba105cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../models_neural/src/layers_embeddings.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.default_max_pos = nn.Parameter(torch.tensor(self.max_position_embs - 1), requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "model = SourceClassifier.load_from_checkpoint(model_path, config=config_dict)\n",
    "if remote:\n",
    "    model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09a669-b6d7-46ef-862a-3a1851dc51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict.include_nones_as_positives = config_dict.train_on_none\n",
    "data_model = SourceClassificationDataModule(\n",
    "    config=config_dict,\n",
    "    data_fp=data_fn,\n",
    "    model_type='roberta',\n",
    "    max_length_seq=2048,\n",
    "    pretrained_model_path=config_dict.pretrained_model_path,\n",
    "    batch_size=1,\n",
    "    spacy_path='en_core_web_lg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "449788a4-751e-47ff-a31b-306dffe12ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 335/335 [08:16<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "data_model.prepare_data()\n",
    "data_model.setup()\n",
    "dataloader = data_model.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a67fd11-ba6b-441a-bb12-a2b8ecf888d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:32<00:00, 52.66it/s]\n"
     ]
    }
   ],
   "source": [
    "all_samples = []\n",
    "for idx, sample in tqdm(enumerate(data_model.test_dataset), total=len(data_model.test_dataset)):\n",
    "    sample = data_model.collate_fn([sample])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids = sample['input_ids'].to('cuda')\n",
    "        attention_mask=sample['attention_mask'].to('cuda')\n",
    "        sentence_ids=sample['target_sentence_ids'].to('cuda')\n",
    "        person_ids = sample['target_person_ids'].to('cuda')\n",
    "        output = model.forward(input_ids=input_ids, attention_mask=attention_mask, target_sentence_ids=sentence_ids, target_person_ids=person_ids)\n",
    "    \n",
    "    sample['pred'] = float(output[1].to('cpu')[0][0])\n",
    "    all_samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76c3ef56-cbaa-4acf-82eb-805909c3db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples_df = pd.DataFrame(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80b9802b-91ad-4e41-9c65-c30e17d12e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = (\n",
    "    all_samples_df[['labels', 'pred']]\n",
    "    .assign(labels=lambda df: df['labels'].apply(lambda x: float(x[0][0])))\n",
    "    .assign(pred=lambda df: df['pred'].apply(expit))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a10dae9-e85d-4b66-8ac9-361e411a8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "43195bef-9441-41e9-85b5-9887e8459bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6701040061199922"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(output_df['labels'], output_df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3b2f4bb9-dd73-4209-a712-c7c0aca7222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "29afa406-884a-4edb-875b-8405c991deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = {}\n",
    "for i in np.arange(0, 1, .001):\n",
    "    f1_scores[i] = f1_score(output_df['labels'], output_df['pred'] > i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f9a749ce-b50f-477e-b0ce-5c6e6efa69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1baaf8cb-a05a-4e8f-972e-65438fecf9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(f1_scores).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f71a6e75-0fb0-467a-8e80-5ecfb04c6ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    863\n",
       "1.0    824\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8c0eca87-f728-4d08-bdba-567371eba624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6563122262046993"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(output_df['labels'], np.ones_like(output_df['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1c4c3-309c-47ed-ad07-de7a5823764b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b4e2ff14-1cf9-49fc-8316-cb983a990e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>target_sentence_ids</th>\n",
       "      <th>target_person_ids</th>\n",
       "      <th>labels</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>input_lens</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[tensor(0), tensor(15545), tensor(661), tenso...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(1.)]]</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[[tensor(14), tensor(6), tensor(9), tensor(12)...</td>\n",
       "      <td>-1.344397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [[tensor(0), tensor(15545), tensor(661), tenso...   \n",
       "\n",
       "                                 target_sentence_ids  \\\n",
       "0  [[tensor(0), tensor(0), tensor(0), tensor(0), ...   \n",
       "\n",
       "                                   target_person_ids          labels  \\\n",
       "0  [[tensor(0), tensor(0), tensor(0), tensor(0), ...  [[tensor(1.)]]   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "\n",
       "                                          input_lens      pred  \n",
       "0  [[tensor(14), tensor(6), tensor(9), tensor(12)... -1.344397  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bc0eb834-394c-4633-8495-f1fb147bb105",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples_df['targeted_sentences'] = all_samples_df.apply(lambda x: x['input_ids'][0, (x['target_sentence_ids'] == 1).nonzero()[:, 1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "71feb7ed-d733-448d-bb47-1facfb68357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples_df['decoded_sentences'] = all_samples_df['targeted_sentences'].apply(data_model.tokenizer.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bacae0e5-b08a-45ce-adc2-e00d33adc542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3213610586011342"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples_df.pipe(lambda df: \n",
    "    f1_score(\n",
    "        df['labels'].apply(lambda x: float(x[0][0])), \n",
    "        df['pred'] > 0\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9ead62bb-311b-4911-b037-30b89cdb4b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>target_sentence_ids</th>\n",
       "      <th>target_person_ids</th>\n",
       "      <th>labels</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>input_lens</th>\n",
       "      <th>pred</th>\n",
       "      <th>targeted_sentences</th>\n",
       "      <th>decoded_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[tensor(0), tensor(15545), tensor(661), tenso...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(1.)]]</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[[tensor(14), tensor(6), tensor(9), tensor(12)...</td>\n",
       "      <td>-1.344397</td>\n",
       "      <td>[tensor(0), tensor(113), tensor(19681), tensor...</td>\n",
       "      <td>&lt;s&gt;\" Tomorrow early morning first I go to morn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[tensor(0), tensor(15545), tensor(661), tenso...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0.)]]</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[[tensor(17), tensor(16), tensor(8), tensor(17...</td>\n",
       "      <td>-0.979630</td>\n",
       "      <td>[tensor(0), tensor(113), tensor(20), tensor(23...</td>\n",
       "      <td>&lt;s&gt;\" The train leaves every morning at 18 AM. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[tensor(0), tensor(15545), tensor(661), tenso...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(1.)]]</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[[tensor(14), tensor(9), tensor(12), tensor(7)...</td>\n",
       "      <td>2.286806</td>\n",
       "      <td>[tensor(0), tensor(113), tensor(4337), tensor(...</td>\n",
       "      <td>&lt;s&gt;\" Every child likes an ice cream. \" said au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[tensor(0), tensor(15545), tensor(661), tenso...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(1.)]]</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[[tensor(15), tensor(12), tensor(14), tensor(1...</td>\n",
       "      <td>-0.586940</td>\n",
       "      <td>[tensor(0), tensor(113), tensor(38), tensor(65...</td>\n",
       "      <td>&lt;s&gt;\" I love my new pets. \" said Jenna Bellman&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[tensor(0), tensor(15545), tensor(661), tenso...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0.)]]</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[[tensor(18), tensor(8), tensor(14), tensor(12...</td>\n",
       "      <td>-1.132871</td>\n",
       "      <td>[tensor(0), tensor(113), tensor(85), tensor(45...</td>\n",
       "      <td>&lt;s&gt;\" It snows a lot in winter in Russia. \" sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>[[tensor(0), tensor(15545), tensor(661), tenso...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(1.)]]</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[[tensor(15), tensor(17), tensor(12), tensor(1...</td>\n",
       "      <td>-0.386626</td>\n",
       "      <td>[tensor(0), tensor(113), tensor(85), tensor(45...</td>\n",
       "      <td>&lt;s&gt;\" It snows a lot in winter in Russia. \" sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>[[tensor(0), tensor(15545), tensor(661), tenso...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(1.)]]</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[[tensor(13), tensor(10), tensor(8), tensor(15...</td>\n",
       "      <td>2.357715</td>\n",
       "      <td>[tensor(0), tensor(113), tensor(1832), tensor(...</td>\n",
       "      <td>&lt;s&gt;\" Do you like spaghetti? \" said Jenna Bellm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>[[tensor(0), tensor(15545), tensor(661), tenso...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0.)]]</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[[tensor(13), tensor(13), tensor(16), tensor(8...</td>\n",
       "      <td>-1.554824</td>\n",
       "      <td>[tensor(0), tensor(113), tensor(264), tensor(4...</td>\n",
       "      <td>&lt;s&gt;\" She does n’t use a computer. \" said autho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>[[tensor(0), tensor(15545), tensor(661), tenso...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(1.)]]</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[[tensor(18), tensor(17), tensor(8), tensor(17...</td>\n",
       "      <td>-1.078834</td>\n",
       "      <td>[tensor(0), tensor(113), tensor(1832), tensor(...</td>\n",
       "      <td>&lt;s&gt;\" Do you like spaghetti? \" said officials&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>[[tensor(0), tensor(15545), tensor(661), tenso...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(0), tensor(0), tensor(0), tensor(0), ...</td>\n",
       "      <td>[[tensor(1.)]]</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[[tensor(22), tensor(8), tensor(15), tensor(17...</td>\n",
       "      <td>-0.974670</td>\n",
       "      <td>[tensor(0), tensor(113), tensor(38), tensor(65...</td>\n",
       "      <td>&lt;s&gt;\" I love my new pets. \" said Robert Smith&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1687 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_ids  \\\n",
       "0     [[tensor(0), tensor(15545), tensor(661), tenso...   \n",
       "1     [[tensor(0), tensor(15545), tensor(661), tenso...   \n",
       "2     [[tensor(0), tensor(15545), tensor(661), tenso...   \n",
       "3     [[tensor(0), tensor(15545), tensor(661), tenso...   \n",
       "4     [[tensor(0), tensor(15545), tensor(661), tenso...   \n",
       "...                                                 ...   \n",
       "1682  [[tensor(0), tensor(15545), tensor(661), tenso...   \n",
       "1683  [[tensor(0), tensor(15545), tensor(661), tenso...   \n",
       "1684  [[tensor(0), tensor(15545), tensor(661), tenso...   \n",
       "1685  [[tensor(0), tensor(15545), tensor(661), tenso...   \n",
       "1686  [[tensor(0), tensor(15545), tensor(661), tenso...   \n",
       "\n",
       "                                    target_sentence_ids  \\\n",
       "0     [[tensor(0), tensor(0), tensor(0), tensor(0), ...   \n",
       "1     [[tensor(0), tensor(0), tensor(0), tensor(0), ...   \n",
       "2     [[tensor(0), tensor(0), tensor(0), tensor(0), ...   \n",
       "3     [[tensor(0), tensor(0), tensor(0), tensor(0), ...   \n",
       "4     [[tensor(0), tensor(0), tensor(0), tensor(0), ...   \n",
       "...                                                 ...   \n",
       "1682  [[tensor(0), tensor(0), tensor(0), tensor(0), ...   \n",
       "1683  [[tensor(0), tensor(0), tensor(0), tensor(0), ...   \n",
       "1684  [[tensor(0), tensor(0), tensor(0), tensor(0), ...   \n",
       "1685  [[tensor(0), tensor(0), tensor(0), tensor(0), ...   \n",
       "1686  [[tensor(0), tensor(0), tensor(0), tensor(0), ...   \n",
       "\n",
       "                                      target_person_ids          labels  \\\n",
       "0     [[tensor(0), tensor(0), tensor(0), tensor(0), ...  [[tensor(1.)]]   \n",
       "1     [[tensor(0), tensor(0), tensor(0), tensor(0), ...  [[tensor(0.)]]   \n",
       "2     [[tensor(0), tensor(0), tensor(0), tensor(0), ...  [[tensor(1.)]]   \n",
       "3     [[tensor(0), tensor(0), tensor(0), tensor(0), ...  [[tensor(1.)]]   \n",
       "4     [[tensor(0), tensor(0), tensor(0), tensor(0), ...  [[tensor(0.)]]   \n",
       "...                                                 ...             ...   \n",
       "1682  [[tensor(0), tensor(0), tensor(0), tensor(0), ...  [[tensor(1.)]]   \n",
       "1683  [[tensor(0), tensor(0), tensor(0), tensor(0), ...  [[tensor(1.)]]   \n",
       "1684  [[tensor(0), tensor(0), tensor(0), tensor(0), ...  [[tensor(0.)]]   \n",
       "1685  [[tensor(0), tensor(0), tensor(0), tensor(0), ...  [[tensor(1.)]]   \n",
       "1686  [[tensor(0), tensor(0), tensor(0), tensor(0), ...  [[tensor(1.)]]   \n",
       "\n",
       "                                         attention_mask  \\\n",
       "0     [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "1     [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "2     [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "3     [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "4     [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "...                                                 ...   \n",
       "1682  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "1683  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "1684  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "1685  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "1686  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "\n",
       "                                             input_lens      pred  \\\n",
       "0     [[tensor(14), tensor(6), tensor(9), tensor(12)... -1.344397   \n",
       "1     [[tensor(17), tensor(16), tensor(8), tensor(17... -0.979630   \n",
       "2     [[tensor(14), tensor(9), tensor(12), tensor(7)...  2.286806   \n",
       "3     [[tensor(15), tensor(12), tensor(14), tensor(1... -0.586940   \n",
       "4     [[tensor(18), tensor(8), tensor(14), tensor(12... -1.132871   \n",
       "...                                                 ...       ...   \n",
       "1682  [[tensor(15), tensor(17), tensor(12), tensor(1... -0.386626   \n",
       "1683  [[tensor(13), tensor(10), tensor(8), tensor(15...  2.357715   \n",
       "1684  [[tensor(13), tensor(13), tensor(16), tensor(8... -1.554824   \n",
       "1685  [[tensor(18), tensor(17), tensor(8), tensor(17... -1.078834   \n",
       "1686  [[tensor(22), tensor(8), tensor(15), tensor(17... -0.974670   \n",
       "\n",
       "                                     targeted_sentences  \\\n",
       "0     [tensor(0), tensor(113), tensor(19681), tensor...   \n",
       "1     [tensor(0), tensor(113), tensor(20), tensor(23...   \n",
       "2     [tensor(0), tensor(113), tensor(4337), tensor(...   \n",
       "3     [tensor(0), tensor(113), tensor(38), tensor(65...   \n",
       "4     [tensor(0), tensor(113), tensor(85), tensor(45...   \n",
       "...                                                 ...   \n",
       "1682  [tensor(0), tensor(113), tensor(85), tensor(45...   \n",
       "1683  [tensor(0), tensor(113), tensor(1832), tensor(...   \n",
       "1684  [tensor(0), tensor(113), tensor(264), tensor(4...   \n",
       "1685  [tensor(0), tensor(113), tensor(1832), tensor(...   \n",
       "1686  [tensor(0), tensor(113), tensor(38), tensor(65...   \n",
       "\n",
       "                                      decoded_sentences  \n",
       "0     <s>\" Tomorrow early morning first I go to morn...  \n",
       "1     <s>\" The train leaves every morning at 18 AM. ...  \n",
       "2     <s>\" Every child likes an ice cream. \" said au...  \n",
       "3     <s>\" I love my new pets. \" said Jenna Bellman</s>  \n",
       "4     <s>\" It snows a lot in winter in Russia. \" sai...  \n",
       "...                                                 ...  \n",
       "1682  <s>\" It snows a lot in winter in Russia. \" sai...  \n",
       "1683  <s>\" Do you like spaghetti? \" said Jenna Bellm...  \n",
       "1684  <s>\" She does n’t use a computer. \" said autho...  \n",
       "1685   <s>\" Do you like spaghetti? \" said officials</s>  \n",
       "1686   <s>\" I love my new pets. \" said Robert Smith</s>  \n",
       "\n",
       "[1687 rows x 9 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79313f20-993b-4e94-a95f-c9306e464e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9970805-dbd5-4a1a-83bc-04f0de9d5607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc14c3-8ff2-4a33-b64b-83fcc96efd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24eecb5-55bf-40dd-a084-2f293df6302d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cee2fbd-abde-4ad6-83f8-3996103338ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9584910-98ba-443a-91c7-b27e9f543964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036b82c-f14e-4f45-a788-1c834b764d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d72c3e-84da-410d-ae9f-ef0d4790c638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30008f25-8d3a-4251-90d8-480d838481e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c149b4-43fb-4405-aa10-5b20a26d93a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0de36-3377-488c-87ed-be482baeb71c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f03d1e2a",
   "metadata": {},
   "source": [
    "# Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa87a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'config-Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. No train on None..json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa8f61-5507-4caf-a4a6-723019dd7092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69fbd4f8",
   "metadata": {},
   "source": [
    "# QA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72e9e1-e3cd-472a-894d-a2c94e320e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_model_path = 'trial-Stage 2: Quote Attribution. Our dataset only.__epoch=05-perplexity=0.00.ckpt'\n",
    "if remote:\n",
    "    # download config\n",
    "    ! aws s3 cp 's3://aspangher/source-exploration/./config-Stage 2: Quote Attribution. Our dataset only..json'  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "                \n",
    "    # download models\n",
    "    ! aws s3 cp \"s3://aspangher/source-exploration/./$qa_model_path\"  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a687f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_out = 'config-%s.json' % \"Stage 2: Quote Attribution. Our dataset only.\"\n",
    "with open(config_out) as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "config_dict = attrdict.AttrDict(config_dict)\n",
    "config_dict.pretrained_files_s3 = config_dict.pretrained_model_path\n",
    "config_dict.model_type = 'roberta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfa6d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SourceQA.load_from_checkpoint(model_path, config=config_dict)\n",
    "if remote:\n",
    "    model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "169d5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = SourceQADataModule(\n",
    "    config=config_dict,\n",
    "    data_fp=data_fn,\n",
    "    model_type='roberta',\n",
    "    max_length_seq=2048,\n",
    "    pretrained_model_path=config_dict.pretrained_model_path,\n",
    "    batch_size=1,\n",
    "    spacy_path='en_core_web_lg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ce97c9e-d866-4e61-9c4a-9ef65fef01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.prepare_data()\n",
    "data_model.setup()\n",
    "dataloader = data_model.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6e7aecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 712/712 [00:32<00:00, 22.18it/s]\n"
     ]
    }
   ],
   "source": [
    "all_samples = []\n",
    "for idx, sample in tqdm(enumerate(data_model.test_dataset), total=len(data_model.test_dataset)):\n",
    "    sample = data_model.collate_fn([sample])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids = sample['input_ids'].to('cuda')\n",
    "        attention_mask=sample['attention_mask'].to('cuda')\n",
    "        sentence_ids=sample['sentence_ids'].to('cuda')\n",
    "        output = model.forward(input_ids=input_ids, attention_mask=attention_mask, sentence_ids=sentence_ids)\n",
    "\n",
    "        start_logits, end_logits = output\n",
    "        start, end = start_logits.argmax().to('cpu'), end_logits.argmax().to('cpu') \n",
    "    \n",
    "    sample['pred_start'] = start\n",
    "    sample['pred_end'] = end\n",
    "    sample['start_logits'] = start_logits.to('cpu')\n",
    "    sample['end_logits'] = end_logits.to('cpu')\n",
    "    all_samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "514f9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.DataFrame(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a4b2cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [['start_positions', 'end_positions', 'pred_start', 'pred_end']]\n",
    "samples_df = (\n",
    "    samples_df\n",
    "        .assign(start_positions=lambda df: df['start_positions'].str.get(0).apply(int))\n",
    "        .assign(end_positions=lambda df: df['end_positions'].str.get(0).apply(int)) \n",
    "        .assign(pred_start=lambda df: df['pred_start'].apply(int)) \n",
    "        .assign(pred_end=lambda df: df['pred_end'].apply(int)) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a4d621f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = (samples_df\n",
    " .assign(true_span=lambda df: \n",
    "         df.apply(lambda x: x['input_ids'][:, x['start_positions']:x['end_positions']], axis=1)\n",
    "           .apply(lambda x: data_model.tokenizer.decode(x[0]))\n",
    "        )\n",
    " .assign(pred_span=lambda df: \n",
    "         df.apply(lambda x: x['input_ids'][:, x['pred_start']:x['pred_end']], axis=1)\n",
    "           .apply(lambda x: data_model.tokenizer.decode(x[0]))\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "274ebbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = samples_df[['true_span', 'pred_span']].applymap(lambda x: x.replace('</s><s>', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6b70d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5bf71697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4470576309257075"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.apply(lambda x: compute_f1(x['pred_span'], x['true_span']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4f818b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43679775280898875"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.apply(lambda x: compute_exact_match(x['pred_span'], x['true_span']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edbf4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f5174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b1fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c27903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794b726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a44f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7134586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012db70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9e26bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52eef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "77642a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_positions</th>\n",
       "      <th>end_positions</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1387</td>\n",
       "      <td>1394</td>\n",
       "      <td>1387</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235</td>\n",
       "      <td>239</td>\n",
       "      <td>240</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>277</td>\n",
       "      <td>279</td>\n",
       "      <td>157</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>363</td>\n",
       "      <td>365</td>\n",
       "      <td>857</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>635</td>\n",
       "      <td>640</td>\n",
       "      <td>1089</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>97</td>\n",
       "      <td>101</td>\n",
       "      <td>97</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>614</td>\n",
       "      <td>618</td>\n",
       "      <td>295</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>472</td>\n",
       "      <td>474</td>\n",
       "      <td>472</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start_positions  end_positions  pred_start  pred_end\n",
       "0                 49             52          49        92\n",
       "1               1387           1394        1387        22\n",
       "2                  1              3          27       335\n",
       "3                235            239         240       239\n",
       "4                277            279         157       159\n",
       "..               ...            ...         ...       ...\n",
       "707              363            365         857       365\n",
       "708              635            640        1089      1093\n",
       "709               97            101          97       101\n",
       "710              614            618         295       777\n",
       "711              472            474         472       474\n",
       "\n",
       "[712 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e4ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e694a6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5196629213483146"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df.pipe(lambda df: df['start_positions'] ==  df['pred_start']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed3a4ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5084269662921348"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df.pipe(lambda df: df['end_positions'] ==  df['pred_end']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc6a3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_overlap(row):\n",
    "    temp_pred_start, temp_pred_end = row[['pred_start', 'pred_end']]\n",
    "    pred_start = min(temp_pred_start, temp_pred_end)\n",
    "    pred_end = max(temp_pred_start, temp_pred_end)\n",
    "    \n",
    "    true_start = row['start_positions']\n",
    "    true_end = row['end_positions']\n",
    "    \n",
    "    start_mark = max(pred_start, true_start)\n",
    "    end_mark = min(pred_end, true_end)\n",
    "    \n",
    "    num = max(0, end_mark - start_mark)\n",
    "    denom = pred_end - pred_start\n",
    "    \n",
    "    return num / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc08c076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43925877688822845"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df.apply(evaluate_overlap, axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268e3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3aadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748f49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "96036e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7df35280",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base-expanded-embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "616a2c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' David W. Eaton'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sample['input_ids'][:, start:end][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4e25e5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(212)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a92556fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(216)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7e423312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_positions': tensor([212]),\n",
       " 'end_positions': tensor([216]),\n",
       " 'input_ids': tensor([[    0, 15545,   661, 18718,   111,  2236,    96,     5,  2625,    81,\n",
       "          25752,     9,   681,     8,  1123, 12252,  2156,  4257,   747, 22884,\n",
       "              5,   810,    14,     5,   609,    64,   278,   160,  3027, 20396,\n",
       "            479,     2,     0,  1708,  4211,   224,    14,    11,     5,   315,\n",
       "            532,  2156, 25752,   111, 26914, 20396,    32,    45,  1537,   479,\n",
       "              2,     0,  1121,   896,  2156,   959,  2156,    10, 22040,     9,\n",
       "          20396,    11,  6055,   624,     5,   375,   292,   107,    34,    57,\n",
       "           9702,     7, 25752,  2156,    50, 29215, 34905,  2156,    11,    61,\n",
       "            514,  2156,  8321,     8,  6255,    32, 22993,    23,   239,  1164,\n",
       "             88,    10,   157, 20463,    11,    10, 14352,  9285,     7,  1108,\n",
       "             62,     5,  3152,     8,   800,   681,     8,  1123,   479,     2,\n",
       "              0,  5975,  2156,  4211,    23,     5,   589,     9,  6501,    54,\n",
       "           8069,   167, 20396,  2156,   583,  2063,  5099,    11,     5,  1353,\n",
       "            233,     9,     5,  2791,  2156,   224,     5,  2677,  5556,    58,\n",
       "          26914,    11,    80,  1319,  4832,    30,  3488,    11,  1164,    25,\n",
       "              5, 25752,  2756,  2156,     8,  2156,    13,    10,    86,    71,\n",
       "              5,   609,    21,  2121,  2156,    30,  1164,  1022,  1146,    15,\n",
       "             30,     5, 16747,  2621,     9, 25752, 12293,   479,     2,     0,\n",
       "             17,    48,     2,     0,   133,   762,  1579,    16,    14,     5,\n",
       "           2270,  1303,     9, 12632,   111, 26914, 38686, 24414,    11,  2027,\n",
       "            896,    16,   430,    31,     5,  1353,   315,   532,  2156,    44,\n",
       "             46,    26,   871,   305,     4, 19712,  2156,    10,  3097,     9,\n",
       "           5473,  6673, 33823,    23,     5,   589,     9,  6501,     8,  1029,\n",
       "            111,  2730,     9,    10,  2225,    11,     5,  8812,  4662,  9072,\n",
       "              5,   557,   479,     2,     0,   133,  4139,   115,   244,  5904,\n",
       "            185,  2402,     7,  1877,   215, 26914, 20396,  2156,    37,    26,\n",
       "            479,     2,     0, 40816,   224,   144,     9,     5,   485, 20396,\n",
       "             11,  4020,     8,    97,  1667,     9,     5,   315,   532,    33,\n",
       "             57,  1726,    30,     5, 17353,     9, 23399,    31,    70,  6134,\n",
       "              9,   681,     8,  1123, 12252,  1195,    87,    30,     5, 25752,\n",
       "            609,  1495,   479,     2,     0,   771,  1988, 24159,    16, 22993,\n",
       "            223,  1164,    88, 12307, 12252, 20463,    88,    10,  6255,  4670,\n",
       "             50,    97, 31582,   868,  9285,  2156,     8,  7964,    88,     5,\n",
       "           3152,   479,     2,     0,  1711,    64,  1303,  1164,  1022,    11,\n",
       "              5,  9285,    14,    64,  4904,     5, 39342,   198,    10,  7684,\n",
       "           2056,  2156,  3735,    41,  8969,    25,     5,  7684, 25843,   479,\n",
       "              2,     0,  1121,     5,  2063,  5099,   443,    11,  6055,  2156,\n",
       "            147,   681,     8,  1123,   451,    33,    57,  7802,    11,   485,\n",
       "            107,    88,    10,  9285,   373,     5,  5620, 12170,   857, 14352,\n",
       "           2156,   656,   557,    56,   450,  5678,   227,     5, 20396,    93,\n",
       "             70,     9,    61,    58,  3694,     8,  1726,   410,  1880,    93,\n",
       "              8, 25752,  2156,  1195,    87, 23399, 12632,   479,     2,     0,\n",
       "           1121,    49,   173,  2156,   925,     4, 19712,     8, 30226,  2753,\n",
       "          13862,   163,  3853,  2156,    10,   618, 33841,  9338,  2156,  1415,\n",
       "             88,     5,  5678,    11,    55,  4617,  2156, 18999, 23956,   414,\n",
       "             31,    10,   651,     9,  2677,  5556,    23,  2063,  5099,    11,\n",
       "            628,   777,     8,   419,   570,  2156,     8,  2189,    31, 12252,\n",
       "            147, 25752,    21, 14196,    23,     5,    86,   479,     2,     0,\n",
       "           1213,   303,    80,  8117,     7,     5, 38686, 24414,   479,     2,\n",
       "              0,  3972,     5,  3017,    11,     5,  7684,  2056,  2156,   144,\n",
       "              9,     5, 20396,  2756,   148,     5, 25752,   609,  1495,  2156,\n",
       "             61,  9200,    62,     7,    10,   353,   479,     2,     0,  3972,\n",
       "              5,  3072,  2156,    89,    58,   367,  3169,  2677,  5556, 25606,\n",
       "             51,  2756, 41870,  7240,    81,   484,   377,    71,     5, 25752,\n",
       "           1249,   479,     2,     0, 14043,     4, 19712,    26,     5, 25752,\n",
       "            609,   115,    28, 26847,     7,   650,  9111, 18740,  2156, 23485,\n",
       "             14,  1504,    88,     5,  3152,  9285,     8,  6042,   464,     5,\n",
       "           3992,  8117,   624,   479,     2,     0,    17,    48,     2,     0,\n",
       "           1106,    89,    16,    10, 11960,  5882,  7684,  2156,   167,  3992,\n",
       "           1022,    32,  7719,     7,  1920,    24,    81,     5,  3543,  2156,\n",
       "             44,    46,    37,    26,   479,     2,     0,  1711,  2092,     7,\n",
       "             28,    99,  1102,    11,     5,  4580,  2698,   479,     2,     0,\n",
       "          11475,     5, 25752,  6897,  2156,   167, 23604, 12327,  5342,  1335,\n",
       "           2156,    37,    26,   479,     2,     0,  1708,    51,   303,    14,\n",
       "              7,     5,  3072,  2156,   203,     9,     5, 25752, 12293,  2442,\n",
       "           9111,    11,     5, 18067, 14352,   479,     2,     0,  1711,    74,\n",
       "            483,     7,    55, 13109,  1164,   624,     5,  7684,  2056,  2156,\n",
       "              8,    55, 20396,    81,    86,   479,     2,     0, 14043,     4,\n",
       "          19712,    26,    37,     8,   643,    58,  7909,    55,   557,     7,\n",
       "           1346,   596,  6055, 17904,  8225,     7, 25752,    87,  4020,     8,\n",
       "             97,  1667,     9,     5,   315,   532,   479,     2,     0,    17,\n",
       "             48,     2,     0,   243,    44,    27,    29,    10,   430,  1068,\n",
       "           2156,    44,    46,    37,    26,  2156,    44,    48,     8,  2969,\n",
       "              5,  9813,     9,     5,  5550,    16,   505,   479,     2,     0,\n",
       "             17,    46,     2]]),\n",
       " 'sentence_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ea99c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
