{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8226fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://artifactory.inf.bloomberg.com/artifactory/api/pypi/bloomberg-pypi/simple/, https://artifactory.inf.bloomberg.com/artifactory/api/pypi/python-dsp-wheels/simple\n",
      "Collecting attrdict\n",
      "  Downloading https://artifactory.inf.bloomberg.com/artifactory/api/pypi/bloomberg-pypi/packages/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: six in /job/.local/lib/python3.7/site-packages (from attrdict) (1.16.0)\n",
      "Installing collected packages: attrdict\n",
      "Successfully installed attrdict-2.0.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from models_neural.quote_attribution.classification_models import SourceQA, SourceClassifier\n",
    "import json\n",
    "try:\n",
    "    import attrdict\n",
    "except:\n",
    "    ! pip install attrdict\n",
    "    import attrdict\n",
    "from models_neural.src.config_helper import TransformersConfig\n",
    "import pandas as pd \n",
    "import zipfile\n",
    "from models_neural.quote_attribution.utils_dataset import SourceQADataModule, SourceClassificationDataModule\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ec1a43-6096-406b-9fc6-f3ea9d4556f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aspangher/spacy/en_core_web_lg/accuracy.json to en_core_web_lg/accuracy.json\n",
      "download: s3://aspangher/spacy/en_core_web_lg/meta.json to en_core_web_lg/meta.json \n",
      "download: s3://aspangher/spacy/en_core_web_lg/ner/moves to en_core_web_lg/ner/moves \n",
      "download: s3://aspangher/spacy/en_core_web_lg/ner/cfg to en_core_web_lg/ner/cfg      \n",
      "download: s3://aspangher/spacy/en_core_web_lg/parser/cfg to en_core_web_lg/parser/cfg\n",
      "download: s3://aspangher/spacy/en_core_web_lg/parser/moves to en_core_web_lg/parser/moves\n",
      "download: s3://aspangher/spacy/en_core_web_lg/tagger/cfg to en_core_web_lg/tagger/cfg \n",
      "download: s3://aspangher/spacy/en_core_web_lg/tagger/tag_map to en_core_web_lg/tagger/tag_map\n",
      "download: s3://aspangher/spacy/en_core_web_lg/tokenizer to en_core_web_lg/tokenizer\n",
      "download: s3://aspangher/spacy/en_core_web_lg/vocab/lookups_extra.bin to en_core_web_lg/vocab/lookups_extra.bin\n",
      "download: s3://aspangher/spacy/en_core_web_lg/vocab/lookups.bin to en_core_web_lg/vocab/lookups.bin\n",
      "download: s3://aspangher/spacy/en_core_web_lg/ner/model to en_core_web_lg/ner/model\n",
      "download: s3://aspangher/spacy/en_core_web_lg/tagger/model to en_core_web_lg/tagger/model\n",
      "download: s3://aspangher/spacy/en_core_web_lg/parser/model to en_core_web_lg/parser/model\n",
      "download: s3://aspangher/spacy/en_core_web_lg/vocab/key2row to en_core_web_lg/vocab/key2row\n",
      "download: s3://aspangher/spacy/en_core_web_lg/vocab/strings.json to en_core_web_lg/vocab/strings.json\n",
      "download: s3://aspangher/spacy/en_core_web_lg/vocab/vectors to en_core_web_lg/vocab/vectors\n",
      "download: s3://aspangher/transformer-pretrained-models/roberta-base-expanded-embeddings.zip to ./roberta-base-expanded-embeddings.zip\n"
     ]
    }
   ],
   "source": [
    "if remote: \n",
    "    # download pretrained models/spacy \n",
    "    ! aws s3 cp --recursive s3://aspangher/spacy/en_core_web_lg/ en_core_web_lg/   --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "    ! aws s3 cp s3://aspangher/transformer-pretrained-models/roberta-base-expanded-embeddings.zip .  --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "    with zipfile.ZipFile('roberta-base-expanded-embeddings.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a747ea62-43da-4ba1-ab59-0d8ea5327644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aspangher/source-exploration/data/our-annotated-data__stage-2.tsv to ./our-annotated-data__stage-2.tsv\n"
     ]
    }
   ],
   "source": [
    "remote = True\n",
    "if remote:\n",
    "    ! aws s3 cp s3://aspangher/source-exploration/data/our-annotated-data__stage-2.tsv  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "    data_fn = 'our-annotated-data__stage-2.tsv'\n",
    "else:\n",
    "    data_fn = '../models_neural/quote_attribution/data/our-annotated-data__stage-2.tsv'\n",
    "data_df = pd.read_csv(data_fn, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939b7e79-244c-4680-9529-d4bed3f89957",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_trained_models = ! aws s3 ls s3://aspangher/source-exploration/./ --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "uploaded_trained_models = list(map(lambda x: ' '.join(x.split()[3:]), uploaded_trained_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da62ad6-51da-48ce-9f99-0d6c49beb53f",
   "metadata": {},
   "source": [
    "# Sanity Check Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "329fcb2e-f245-40eb-8e67-664a90e38ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aspangher/source-exploration/data/quote-attribution-classification__sanity-check-data.tsv to ./quote-attribution-classification__sanity-check-data.tsv\n"
     ]
    }
   ],
   "source": [
    "remote = True\n",
    "if remote:\n",
    "    ! aws s3 cp s3://aspangher/source-exploration/data/quote-attribution-classification__sanity-check-data.tsv  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "    data_fn = 'quote-attribution-classification__sanity-check-data.tsv'\n",
    "else:\n",
    "    data_fn = '../models_neural/quote_attribution/data/quote-attribution-classification__sanity-check-data.tsv'\n",
    "data_df = pd.read_csv(data_fn, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0185bec1-9934-4071-a61d-87ae8b703e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. No train on None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e758794-7ebc-403b-a671-94b941fd60b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aspangher/source-exploration/./config-Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. No train on None..json to ./config-Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. No train on None..json\n",
      "download: s3://aspangher/source-exploration/./trial-Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. No train on None.__epoch=09-perplexity=0.00.ckpt to ./trial-Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. No train on None.__epoch=09-perplexity=0.00.ckpt\n"
     ]
    }
   ],
   "source": [
    "paths = list(filter(lambda x: model_name in x, uploaded_trained_models))\n",
    "model_path = list(filter(lambda x: 'trial-' in x, paths))[0]\n",
    "config_path = list(filter(lambda x: 'config-' in x, paths))[0]\n",
    "if remote:\n",
    "    # download config\n",
    "    ! aws s3 cp \"s3://aspangher/source-exploration/./$config_path\"  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "                \n",
    "    # download models\n",
    "    ! aws s3 cp \"s3://aspangher/source-exploration/./$model_path\"  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "974b5a4e-5363-4b1c-8878-8d5839830bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_path) as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "config_dict = attrdict.AttrDict(config_dict)\n",
    "config_dict.pretrained_files_s3 = config_dict.pretrained_model_path\n",
    "config_dict.model_type = 'roberta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a269a9c-5bbd-4a76-bb03-1eaeba105cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../models_neural/src/layers_embeddings.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.default_max_pos = nn.Parameter(torch.tensor(self.max_position_embs - 1), requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "model = SourceClassifier.load_from_checkpoint(model_path, config=config_dict)\n",
    "if remote:\n",
    "    model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e1e8b7e-1343-4c6d-ae61-b0637258bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = SourceClassificationDataModule(\n",
    "    config=config_dict,\n",
    "    data_fp=data_fn,\n",
    "    model_type='roberta',\n",
    "    max_length_seq=2048,\n",
    "    pretrained_model_path=config_dict.pretrained_model_path,\n",
    "    batch_size=1,\n",
    "    spacy_path='en_core_web_lg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449788a4-751e-47ff-a31b-306dffe12ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 88/335 [02:07<04:47,  1.16s/it] "
     ]
    }
   ],
   "source": [
    "data_model.prepare_data()\n",
    "data_model.setup()\n",
    "dataloader = data_model.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549300a8-f37d-4463-89ff-ba158dabcbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67fd11-ba6b-441a-bb12-a2b8ecf888d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9584910-98ba-443a-91c7-b27e9f543964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036b82c-f14e-4f45-a788-1c834b764d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d72c3e-84da-410d-ae9f-ef0d4790c638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0de36-3377-488c-87ed-be482baeb71c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f03d1e2a",
   "metadata": {},
   "source": [
    "# Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa87a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'config-Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. No train on None..json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59fbbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69fbd4f8",
   "metadata": {},
   "source": [
    "# QA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72e9e1-e3cd-472a-894d-a2c94e320e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_model_path = 'trial-Stage 2: Quote Attribution. Our dataset only.__epoch=05-perplexity=0.00.ckpt'\n",
    "if remote:\n",
    "    # download config\n",
    "    ! aws s3 cp 's3://aspangher/source-exploration/./config-Stage 2: Quote Attribution. Our dataset only..json'  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "                \n",
    "    # download models\n",
    "    ! aws s3 cp \"s3://aspangher/source-exploration/./$qa_model_path\"  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf9be6-b1f2-4d96-80ea-75bb65727546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e792dd-ac7c-4e03-a4bf-c76b51aaebf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a687f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_out = 'config-%s.json' % \"Stage 2: Quote Attribution. Our dataset only.\"\n",
    "with open(config_out) as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "config_dict = attrdict.AttrDict(config_dict)\n",
    "config_dict.pretrained_files_s3 = config_dict.pretrained_model_path\n",
    "config_dict.model_type = 'roberta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfa6d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SourceQA.load_from_checkpoint(model_path, config=config_dict)\n",
    "if remote:\n",
    "    model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "169d5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = SourceQADataModule(\n",
    "    config=config_dict,\n",
    "    data_fp=data_fn,\n",
    "    model_type='roberta',\n",
    "    max_length_seq=2048,\n",
    "    pretrained_model_path=config_dict.pretrained_model_path,\n",
    "    batch_size=1,\n",
    "    spacy_path='en_core_web_lg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ce97c9e-d866-4e61-9c4a-9ef65fef01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.prepare_data()\n",
    "data_model.setup()\n",
    "dataloader = data_model.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6e7aecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 712/712 [00:32<00:00, 22.18it/s]\n"
     ]
    }
   ],
   "source": [
    "all_samples = []\n",
    "for idx, sample in tqdm(enumerate(data_model.test_dataset), total=len(data_model.test_dataset)):\n",
    "    sample = data_model.collate_fn([sample])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids = sample['input_ids'].to('cuda')\n",
    "        attention_mask=sample['attention_mask'].to('cuda')\n",
    "        sentence_ids=sample['sentence_ids'].to('cuda')\n",
    "        output = model.forward(input_ids=input_ids, attention_mask=attention_mask, sentence_ids=sentence_ids)\n",
    "\n",
    "        start_logits, end_logits = output\n",
    "        start, end = start_logits.argmax().to('cpu'), end_logits.argmax().to('cpu') \n",
    "    \n",
    "    sample['pred_start'] = start\n",
    "    sample['pred_end'] = end\n",
    "    sample['start_logits'] = start_logits.to('cpu')\n",
    "    sample['end_logits'] = end_logits.to('cpu')\n",
    "    all_samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "514f9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.DataFrame(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a4b2cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [['start_positions', 'end_positions', 'pred_start', 'pred_end']]\n",
    "samples_df = (\n",
    "    samples_df\n",
    "        .assign(start_positions=lambda df: df['start_positions'].str.get(0).apply(int))\n",
    "        .assign(end_positions=lambda df: df['end_positions'].str.get(0).apply(int)) \n",
    "        .assign(pred_start=lambda df: df['pred_start'].apply(int)) \n",
    "        .assign(pred_end=lambda df: df['pred_end'].apply(int)) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a4d621f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = (samples_df\n",
    " .assign(true_span=lambda df: \n",
    "         df.apply(lambda x: x['input_ids'][:, x['start_positions']:x['end_positions']], axis=1)\n",
    "           .apply(lambda x: data_model.tokenizer.decode(x[0]))\n",
    "        )\n",
    " .assign(pred_span=lambda df: \n",
    "         df.apply(lambda x: x['input_ids'][:, x['pred_start']:x['pred_end']], axis=1)\n",
    "           .apply(lambda x: data_model.tokenizer.decode(x[0]))\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "274ebbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = samples_df[['true_span', 'pred_span']].applymap(lambda x: x.replace('</s><s>', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6b70d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5bf71697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4470576309257075"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.apply(lambda x: compute_f1(x['pred_span'], x['true_span']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4f818b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43679775280898875"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.apply(lambda x: compute_exact_match(x['pred_span'], x['true_span']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edbf4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f5174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b1fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c27903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794b726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a44f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7134586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012db70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9e26bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52eef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "77642a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_positions</th>\n",
       "      <th>end_positions</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1387</td>\n",
       "      <td>1394</td>\n",
       "      <td>1387</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235</td>\n",
       "      <td>239</td>\n",
       "      <td>240</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>277</td>\n",
       "      <td>279</td>\n",
       "      <td>157</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>363</td>\n",
       "      <td>365</td>\n",
       "      <td>857</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>635</td>\n",
       "      <td>640</td>\n",
       "      <td>1089</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>97</td>\n",
       "      <td>101</td>\n",
       "      <td>97</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>614</td>\n",
       "      <td>618</td>\n",
       "      <td>295</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>472</td>\n",
       "      <td>474</td>\n",
       "      <td>472</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start_positions  end_positions  pred_start  pred_end\n",
       "0                 49             52          49        92\n",
       "1               1387           1394        1387        22\n",
       "2                  1              3          27       335\n",
       "3                235            239         240       239\n",
       "4                277            279         157       159\n",
       "..               ...            ...         ...       ...\n",
       "707              363            365         857       365\n",
       "708              635            640        1089      1093\n",
       "709               97            101          97       101\n",
       "710              614            618         295       777\n",
       "711              472            474         472       474\n",
       "\n",
       "[712 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e4ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e694a6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5196629213483146"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df.pipe(lambda df: df['start_positions'] ==  df['pred_start']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed3a4ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5084269662921348"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df.pipe(lambda df: df['end_positions'] ==  df['pred_end']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc6a3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_overlap(row):\n",
    "    temp_pred_start, temp_pred_end = row[['pred_start', 'pred_end']]\n",
    "    pred_start = min(temp_pred_start, temp_pred_end)\n",
    "    pred_end = max(temp_pred_start, temp_pred_end)\n",
    "    \n",
    "    true_start = row['start_positions']\n",
    "    true_end = row['end_positions']\n",
    "    \n",
    "    start_mark = max(pred_start, true_start)\n",
    "    end_mark = min(pred_end, true_end)\n",
    "    \n",
    "    num = max(0, end_mark - start_mark)\n",
    "    denom = pred_end - pred_start\n",
    "    \n",
    "    return num / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc08c076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43925877688822845"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df.apply(evaluate_overlap, axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268e3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3aadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748f49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "96036e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7df35280",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base-expanded-embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "616a2c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' David W. Eaton'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sample['input_ids'][:, start:end][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4e25e5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(212)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a92556fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(216)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7e423312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_positions': tensor([212]),\n",
       " 'end_positions': tensor([216]),\n",
       " 'input_ids': tensor([[    0, 15545,   661, 18718,   111,  2236,    96,     5,  2625,    81,\n",
       "          25752,     9,   681,     8,  1123, 12252,  2156,  4257,   747, 22884,\n",
       "              5,   810,    14,     5,   609,    64,   278,   160,  3027, 20396,\n",
       "            479,     2,     0,  1708,  4211,   224,    14,    11,     5,   315,\n",
       "            532,  2156, 25752,   111, 26914, 20396,    32,    45,  1537,   479,\n",
       "              2,     0,  1121,   896,  2156,   959,  2156,    10, 22040,     9,\n",
       "          20396,    11,  6055,   624,     5,   375,   292,   107,    34,    57,\n",
       "           9702,     7, 25752,  2156,    50, 29215, 34905,  2156,    11,    61,\n",
       "            514,  2156,  8321,     8,  6255,    32, 22993,    23,   239,  1164,\n",
       "             88,    10,   157, 20463,    11,    10, 14352,  9285,     7,  1108,\n",
       "             62,     5,  3152,     8,   800,   681,     8,  1123,   479,     2,\n",
       "              0,  5975,  2156,  4211,    23,     5,   589,     9,  6501,    54,\n",
       "           8069,   167, 20396,  2156,   583,  2063,  5099,    11,     5,  1353,\n",
       "            233,     9,     5,  2791,  2156,   224,     5,  2677,  5556,    58,\n",
       "          26914,    11,    80,  1319,  4832,    30,  3488,    11,  1164,    25,\n",
       "              5, 25752,  2756,  2156,     8,  2156,    13,    10,    86,    71,\n",
       "              5,   609,    21,  2121,  2156,    30,  1164,  1022,  1146,    15,\n",
       "             30,     5, 16747,  2621,     9, 25752, 12293,   479,     2,     0,\n",
       "             17,    48,     2,     0,   133,   762,  1579,    16,    14,     5,\n",
       "           2270,  1303,     9, 12632,   111, 26914, 38686, 24414,    11,  2027,\n",
       "            896,    16,   430,    31,     5,  1353,   315,   532,  2156,    44,\n",
       "             46,    26,   871,   305,     4, 19712,  2156,    10,  3097,     9,\n",
       "           5473,  6673, 33823,    23,     5,   589,     9,  6501,     8,  1029,\n",
       "            111,  2730,     9,    10,  2225,    11,     5,  8812,  4662,  9072,\n",
       "              5,   557,   479,     2,     0,   133,  4139,   115,   244,  5904,\n",
       "            185,  2402,     7,  1877,   215, 26914, 20396,  2156,    37,    26,\n",
       "            479,     2,     0, 40816,   224,   144,     9,     5,   485, 20396,\n",
       "             11,  4020,     8,    97,  1667,     9,     5,   315,   532,    33,\n",
       "             57,  1726,    30,     5, 17353,     9, 23399,    31,    70,  6134,\n",
       "              9,   681,     8,  1123, 12252,  1195,    87,    30,     5, 25752,\n",
       "            609,  1495,   479,     2,     0,   771,  1988, 24159,    16, 22993,\n",
       "            223,  1164,    88, 12307, 12252, 20463,    88,    10,  6255,  4670,\n",
       "             50,    97, 31582,   868,  9285,  2156,     8,  7964,    88,     5,\n",
       "           3152,   479,     2,     0,  1711,    64,  1303,  1164,  1022,    11,\n",
       "              5,  9285,    14,    64,  4904,     5, 39342,   198,    10,  7684,\n",
       "           2056,  2156,  3735,    41,  8969,    25,     5,  7684, 25843,   479,\n",
       "              2,     0,  1121,     5,  2063,  5099,   443,    11,  6055,  2156,\n",
       "            147,   681,     8,  1123,   451,    33,    57,  7802,    11,   485,\n",
       "            107,    88,    10,  9285,   373,     5,  5620, 12170,   857, 14352,\n",
       "           2156,   656,   557,    56,   450,  5678,   227,     5, 20396,    93,\n",
       "             70,     9,    61,    58,  3694,     8,  1726,   410,  1880,    93,\n",
       "              8, 25752,  2156,  1195,    87, 23399, 12632,   479,     2,     0,\n",
       "           1121,    49,   173,  2156,   925,     4, 19712,     8, 30226,  2753,\n",
       "          13862,   163,  3853,  2156,    10,   618, 33841,  9338,  2156,  1415,\n",
       "             88,     5,  5678,    11,    55,  4617,  2156, 18999, 23956,   414,\n",
       "             31,    10,   651,     9,  2677,  5556,    23,  2063,  5099,    11,\n",
       "            628,   777,     8,   419,   570,  2156,     8,  2189,    31, 12252,\n",
       "            147, 25752,    21, 14196,    23,     5,    86,   479,     2,     0,\n",
       "           1213,   303,    80,  8117,     7,     5, 38686, 24414,   479,     2,\n",
       "              0,  3972,     5,  3017,    11,     5,  7684,  2056,  2156,   144,\n",
       "              9,     5, 20396,  2756,   148,     5, 25752,   609,  1495,  2156,\n",
       "             61,  9200,    62,     7,    10,   353,   479,     2,     0,  3972,\n",
       "              5,  3072,  2156,    89,    58,   367,  3169,  2677,  5556, 25606,\n",
       "             51,  2756, 41870,  7240,    81,   484,   377,    71,     5, 25752,\n",
       "           1249,   479,     2,     0, 14043,     4, 19712,    26,     5, 25752,\n",
       "            609,   115,    28, 26847,     7,   650,  9111, 18740,  2156, 23485,\n",
       "             14,  1504,    88,     5,  3152,  9285,     8,  6042,   464,     5,\n",
       "           3992,  8117,   624,   479,     2,     0,    17,    48,     2,     0,\n",
       "           1106,    89,    16,    10, 11960,  5882,  7684,  2156,   167,  3992,\n",
       "           1022,    32,  7719,     7,  1920,    24,    81,     5,  3543,  2156,\n",
       "             44,    46,    37,    26,   479,     2,     0,  1711,  2092,     7,\n",
       "             28,    99,  1102,    11,     5,  4580,  2698,   479,     2,     0,\n",
       "          11475,     5, 25752,  6897,  2156,   167, 23604, 12327,  5342,  1335,\n",
       "           2156,    37,    26,   479,     2,     0,  1708,    51,   303,    14,\n",
       "              7,     5,  3072,  2156,   203,     9,     5, 25752, 12293,  2442,\n",
       "           9111,    11,     5, 18067, 14352,   479,     2,     0,  1711,    74,\n",
       "            483,     7,    55, 13109,  1164,   624,     5,  7684,  2056,  2156,\n",
       "              8,    55, 20396,    81,    86,   479,     2,     0, 14043,     4,\n",
       "          19712,    26,    37,     8,   643,    58,  7909,    55,   557,     7,\n",
       "           1346,   596,  6055, 17904,  8225,     7, 25752,    87,  4020,     8,\n",
       "             97,  1667,     9,     5,   315,   532,   479,     2,     0,    17,\n",
       "             48,     2,     0,   243,    44,    27,    29,    10,   430,  1068,\n",
       "           2156,    44,    46,    37,    26,  2156,    44,    48,     8,  2969,\n",
       "              5,  9813,     9,     5,  5550,    16,   505,   479,     2,     0,\n",
       "             17,    46,     2]]),\n",
       " 'sentence_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ea99c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
