{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "098e77c9-665f-4813-935f-9209ce42b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_neural.quote_attribution.classification_models import SourceQA\n",
    "import json\n",
    "import attrdict\n",
    "from models_neural.src.config_helper import TransformersConfig\n",
    "import pandas as pd \n",
    "import zipfile\n",
    "from models_neural.quote_attribution.utils_dataset import SourceQADataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c08bd-97d1-448d-b6ec-ba1a077cdaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model \n",
    "! aws s3 cp s3://aspangher/transformer-pretrained-models/roberta-base-expanded-embeddings.zip .  --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "with zipfile.ZipFile('roberta-base-expanded-embeddings.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "    \n",
    "# download dataset\n",
    "! aws s3 cp s3://aspangher/source-exploration/./config-Stage\\ 2\\:\\ Quote\\ Attribution.\\ Our\\ dataset\\ only..json  . --endpoint http://s3.dev.obdc.bcs.bloomberg.com\n",
    "            \n",
    "# download spacy\n",
    "! aws s3 cp --recursive s3://aspangher/spacy/en_core_web_lg/ en_core_web_lg/   --endpoint http://s3.dev.obdc.bcs.bloomberg.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2439a53-03fa-4766-9fa2-0116ea6c3a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fn = 'our-annotated-data__stage-2.tsv'\n",
    "data_df = pd.read_csv(data_fn, sep='\\t', header=None)\n",
    "model_path = 'trial-Stage 2: Quote Attribution. Our dataset only.__epoch=05-perplexity=0.00.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd76811-d328-43ca-b4e3-9ea32fe037ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_out = 'config-%s.json' % \"Stage 2: Quote Attribution. Our dataset only.\"\n",
    "with open(config_out) as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "config_dict = attrdict.AttrDict(config_dict)\n",
    "config_dict.pretrained_files_s3 = config_dict.pretrained_model_path\n",
    "config_dict.model_type = 'roberta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c0039b-8adb-480c-8d2f-1c09fdfa9e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SourceQA.load_from_checkpoint(model_path, config=config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13fab634-ffb1-4b92-ac80-f9c53c9073ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = SourceQADataModule(\n",
    "    config=config_dict,\n",
    "    data_fp=data_fn,\n",
    "    model_type='roberta',\n",
    "    max_length_seq=2048,\n",
    "    pretrained_model_path=config_dict.pretrained_model_path,\n",
    "    batch_size=1,\n",
    "    spacy_path='en_core_web_lg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8afaa016-5932-4729-b0e7-de5c742d80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea8c70ff-cebf-49ac-8964-d2b96e7b3d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 335/335 [02:10<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "data_model.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac0be4d2-a57e-49b2-9fa6-608b11e7d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data_model.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2fa8d9a-05c9-4bf0-ad9b-f850583144af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acc30ff7-7deb-478c-a12e-4852f5c93fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "621a38ee-231d-425b-8f9f-d6de072ad273",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sample in enumerate(dataloader):\n",
    "    sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abbe7b81-7484-4f1c-9d4c-540933a857e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed4ab731-47cc-4832-ae81-9e6389060a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['doc_idx', 'source_head', 'start_position', 'end_position', 'context', 'sentence_indicator_tokens'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model.test_dataset[idx].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd8b7095-9eed-4dca-8701-93f3d6dd97ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model.test_dataset[idx]['start_position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "37c0e67e-8a1c-4083-9201-b61827577758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_model.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "305bec07-f482-49e2-9068-26f109dc5bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_model.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e112b48-572d-4ed4-9fce-1ba3e8d62689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4392b03a-8519-4e07-b223-70974cfcb08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb2ed386-6631-4df2-9a24-23da1b690256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 712/712 [00:32<00:00, 22.18it/s]\n"
     ]
    }
   ],
   "source": [
    "all_samples = []\n",
    "for idx, sample in tqdm(enumerate(data_model.test_dataset), total=len(data_model.test_dataset)):\n",
    "    sample = data_model.collate_fn([sample])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids = sample['input_ids'].to('cuda')\n",
    "        attention_mask=sample['attention_mask'].to('cuda')\n",
    "        sentence_ids=sample['sentence_ids'].to('cuda')\n",
    "        output = model.forward(input_ids=input_ids, attention_mask=attention_mask, sentence_ids=sentence_ids)\n",
    "\n",
    "        start_logits, end_logits = output\n",
    "        start, end = start_logits.argmax().to('cpu'), end_logits.argmax().to('cpu') \n",
    "    \n",
    "    sample['pred_start'] = start\n",
    "    sample['pred_end'] = end\n",
    "    sample['start_logits'] = start_logits.to('cpu')\n",
    "    sample['end_logits'] = end_logits.to('cpu')\n",
    "    all_samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18932829-d1d0-41c2-89c8-a85ea1930a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.DataFrame(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3e4f93a-1c84-418a-afd9-071ebeaa06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_end_df = (samples_df[['start_positions', 'end_positions', 'pred_start', 'pred_end']]\n",
    "    .assign(start_positions=lambda df: df['start_positions'].str.get(0).apply(int))\n",
    "    .assign(end_positions=lambda df: df['end_positions'].str.get(0).apply(int)) \n",
    "    .assign(pred_start=lambda df: df['pred_start'].apply(int)) \n",
    "    .assign(pred_end=lambda df: df['pred_end'].apply(int)) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de6a5201-7fea-4dad-8e4c-3a90004dd764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d1ae9-c9d7-42bb-b558-432bff707682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10fc15f3-54b2-4df0-b7c5-69d3946eadee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_positions</th>\n",
       "      <th>end_positions</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1387</td>\n",
       "      <td>1394</td>\n",
       "      <td>1387</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235</td>\n",
       "      <td>239</td>\n",
       "      <td>240</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>277</td>\n",
       "      <td>279</td>\n",
       "      <td>157</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>363</td>\n",
       "      <td>365</td>\n",
       "      <td>857</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>635</td>\n",
       "      <td>640</td>\n",
       "      <td>1089</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>97</td>\n",
       "      <td>101</td>\n",
       "      <td>97</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>614</td>\n",
       "      <td>618</td>\n",
       "      <td>295</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>472</td>\n",
       "      <td>474</td>\n",
       "      <td>472</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start_positions  end_positions  pred_start  pred_end\n",
       "0                 49             52          49        92\n",
       "1               1387           1394        1387        22\n",
       "2                  1              3          27       335\n",
       "3                235            239         240       239\n",
       "4                277            279         157       159\n",
       "..               ...            ...         ...       ...\n",
       "707              363            365         857       365\n",
       "708              635            640        1089      1093\n",
       "709               97            101          97       101\n",
       "710              614            618         295       777\n",
       "711              472            474         472       474\n",
       "\n",
       "[712 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067113a-53d7-4f0f-bdbf-8d35887b6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "770e3928-77f5-42f7-9df8-c068bec684cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5196629213483146"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df.pipe(lambda df: df['start_positions'] ==  df['pred_start']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2050a40e-9cac-4433-9044-a6cf9c5c4036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5084269662921348"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df.pipe(lambda df: df['end_positions'] ==  df['pred_end']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70425f7f-c735-48f6-8deb-52d16b0f109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_overlap(row):\n",
    "    temp_pred_start, temp_pred_end = row[['pred_start', 'pred_end']]\n",
    "    pred_start = min(temp_pred_start, temp_pred_end)\n",
    "    pred_end = max(temp_pred_start, temp_pred_end)\n",
    "    \n",
    "    true_start = row['start_positions']\n",
    "    true_end = row['end_positions']\n",
    "    \n",
    "    start_mark = max(pred_start, true_start)\n",
    "    end_mark = min(pred_end, true_end)\n",
    "    \n",
    "    num = max(0, end_mark - start_mark)\n",
    "    denom = pred_end - pred_start\n",
    "    \n",
    "    return num / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4b441bc1-759d-46ba-9b34-795fbec2cc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43925877688822845"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_df.apply(evaluate_overlap, axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da5616-30d6-4591-a4c8-34bcaaeb039c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f061b18-584f-40fd-afc2-e8d8ecfe4ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8b216-2b2f-46d2-8e97-002e41326ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f5981eaa-0b2e-48f3-8cbf-9738942d4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a5efe0b9-baa5-4dce-8086-8a4ff0d0f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base-expanded-embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "94fc4f96-e8cd-46e5-a98a-35720f5a45b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' David W. Eaton'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sample['input_ids'][:, start:end][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "146f477b-fc46-4fa6-80e1-f81433c84182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(212)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3f343403-19a5-40ff-87df-2a4af80b6130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(216)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "395a9774-8be8-4d15-adbc-493534b56cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_positions': tensor([212]),\n",
       " 'end_positions': tensor([216]),\n",
       " 'input_ids': tensor([[    0, 15545,   661, 18718,   111,  2236,    96,     5,  2625,    81,\n",
       "          25752,     9,   681,     8,  1123, 12252,  2156,  4257,   747, 22884,\n",
       "              5,   810,    14,     5,   609,    64,   278,   160,  3027, 20396,\n",
       "            479,     2,     0,  1708,  4211,   224,    14,    11,     5,   315,\n",
       "            532,  2156, 25752,   111, 26914, 20396,    32,    45,  1537,   479,\n",
       "              2,     0,  1121,   896,  2156,   959,  2156,    10, 22040,     9,\n",
       "          20396,    11,  6055,   624,     5,   375,   292,   107,    34,    57,\n",
       "           9702,     7, 25752,  2156,    50, 29215, 34905,  2156,    11,    61,\n",
       "            514,  2156,  8321,     8,  6255,    32, 22993,    23,   239,  1164,\n",
       "             88,    10,   157, 20463,    11,    10, 14352,  9285,     7,  1108,\n",
       "             62,     5,  3152,     8,   800,   681,     8,  1123,   479,     2,\n",
       "              0,  5975,  2156,  4211,    23,     5,   589,     9,  6501,    54,\n",
       "           8069,   167, 20396,  2156,   583,  2063,  5099,    11,     5,  1353,\n",
       "            233,     9,     5,  2791,  2156,   224,     5,  2677,  5556,    58,\n",
       "          26914,    11,    80,  1319,  4832,    30,  3488,    11,  1164,    25,\n",
       "              5, 25752,  2756,  2156,     8,  2156,    13,    10,    86,    71,\n",
       "              5,   609,    21,  2121,  2156,    30,  1164,  1022,  1146,    15,\n",
       "             30,     5, 16747,  2621,     9, 25752, 12293,   479,     2,     0,\n",
       "             17,    48,     2,     0,   133,   762,  1579,    16,    14,     5,\n",
       "           2270,  1303,     9, 12632,   111, 26914, 38686, 24414,    11,  2027,\n",
       "            896,    16,   430,    31,     5,  1353,   315,   532,  2156,    44,\n",
       "             46,    26,   871,   305,     4, 19712,  2156,    10,  3097,     9,\n",
       "           5473,  6673, 33823,    23,     5,   589,     9,  6501,     8,  1029,\n",
       "            111,  2730,     9,    10,  2225,    11,     5,  8812,  4662,  9072,\n",
       "              5,   557,   479,     2,     0,   133,  4139,   115,   244,  5904,\n",
       "            185,  2402,     7,  1877,   215, 26914, 20396,  2156,    37,    26,\n",
       "            479,     2,     0, 40816,   224,   144,     9,     5,   485, 20396,\n",
       "             11,  4020,     8,    97,  1667,     9,     5,   315,   532,    33,\n",
       "             57,  1726,    30,     5, 17353,     9, 23399,    31,    70,  6134,\n",
       "              9,   681,     8,  1123, 12252,  1195,    87,    30,     5, 25752,\n",
       "            609,  1495,   479,     2,     0,   771,  1988, 24159,    16, 22993,\n",
       "            223,  1164,    88, 12307, 12252, 20463,    88,    10,  6255,  4670,\n",
       "             50,    97, 31582,   868,  9285,  2156,     8,  7964,    88,     5,\n",
       "           3152,   479,     2,     0,  1711,    64,  1303,  1164,  1022,    11,\n",
       "              5,  9285,    14,    64,  4904,     5, 39342,   198,    10,  7684,\n",
       "           2056,  2156,  3735,    41,  8969,    25,     5,  7684, 25843,   479,\n",
       "              2,     0,  1121,     5,  2063,  5099,   443,    11,  6055,  2156,\n",
       "            147,   681,     8,  1123,   451,    33,    57,  7802,    11,   485,\n",
       "            107,    88,    10,  9285,   373,     5,  5620, 12170,   857, 14352,\n",
       "           2156,   656,   557,    56,   450,  5678,   227,     5, 20396,    93,\n",
       "             70,     9,    61,    58,  3694,     8,  1726,   410,  1880,    93,\n",
       "              8, 25752,  2156,  1195,    87, 23399, 12632,   479,     2,     0,\n",
       "           1121,    49,   173,  2156,   925,     4, 19712,     8, 30226,  2753,\n",
       "          13862,   163,  3853,  2156,    10,   618, 33841,  9338,  2156,  1415,\n",
       "             88,     5,  5678,    11,    55,  4617,  2156, 18999, 23956,   414,\n",
       "             31,    10,   651,     9,  2677,  5556,    23,  2063,  5099,    11,\n",
       "            628,   777,     8,   419,   570,  2156,     8,  2189,    31, 12252,\n",
       "            147, 25752,    21, 14196,    23,     5,    86,   479,     2,     0,\n",
       "           1213,   303,    80,  8117,     7,     5, 38686, 24414,   479,     2,\n",
       "              0,  3972,     5,  3017,    11,     5,  7684,  2056,  2156,   144,\n",
       "              9,     5, 20396,  2756,   148,     5, 25752,   609,  1495,  2156,\n",
       "             61,  9200,    62,     7,    10,   353,   479,     2,     0,  3972,\n",
       "              5,  3072,  2156,    89,    58,   367,  3169,  2677,  5556, 25606,\n",
       "             51,  2756, 41870,  7240,    81,   484,   377,    71,     5, 25752,\n",
       "           1249,   479,     2,     0, 14043,     4, 19712,    26,     5, 25752,\n",
       "            609,   115,    28, 26847,     7,   650,  9111, 18740,  2156, 23485,\n",
       "             14,  1504,    88,     5,  3152,  9285,     8,  6042,   464,     5,\n",
       "           3992,  8117,   624,   479,     2,     0,    17,    48,     2,     0,\n",
       "           1106,    89,    16,    10, 11960,  5882,  7684,  2156,   167,  3992,\n",
       "           1022,    32,  7719,     7,  1920,    24,    81,     5,  3543,  2156,\n",
       "             44,    46,    37,    26,   479,     2,     0,  1711,  2092,     7,\n",
       "             28,    99,  1102,    11,     5,  4580,  2698,   479,     2,     0,\n",
       "          11475,     5, 25752,  6897,  2156,   167, 23604, 12327,  5342,  1335,\n",
       "           2156,    37,    26,   479,     2,     0,  1708,    51,   303,    14,\n",
       "              7,     5,  3072,  2156,   203,     9,     5, 25752, 12293,  2442,\n",
       "           9111,    11,     5, 18067, 14352,   479,     2,     0,  1711,    74,\n",
       "            483,     7,    55, 13109,  1164,   624,     5,  7684,  2056,  2156,\n",
       "              8,    55, 20396,    81,    86,   479,     2,     0, 14043,     4,\n",
       "          19712,    26,    37,     8,   643,    58,  7909,    55,   557,     7,\n",
       "           1346,   596,  6055, 17904,  8225,     7, 25752,    87,  4020,     8,\n",
       "             97,  1667,     9,     5,   315,   532,   479,     2,     0,    17,\n",
       "             48,     2,     0,   243,    44,    27,    29,    10,   430,  1068,\n",
       "           2156,    44,    46,    37,    26,  2156,    44,    48,     8,  2969,\n",
       "              5,  9813,     9,     5,  5550,    16,   505,   479,     2,     0,\n",
       "             17,    46,     2]]),\n",
       " 'sentence_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650d6b7-b4ce-4d33-a658-61d28e50be58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
