{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_output = '../models_neural/quote_attribution/model_output/version_10/events.out.tfevents.1665116328.compute-2dgtl-1665115287.1.0'\n",
    "# path_to_output = '../models_neural/quote_attribution/model_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd \n",
    "from tensorboard_reducer import load_tb_events, reduce_events, write_csv, write_tb_events\n",
    "import yaml\n",
    "import glob\n",
    "\n",
    "def get_events(version_num, path_to_ver):\n",
    "    if isinstance(version_num, (str, int)):\n",
    "        version_num = [version_num]    \n",
    "    events_files = []\n",
    "    for v in version_num:\n",
    "        events_file = path_to_ver + '/version_%s' % v\n",
    "        events_files.append(events_file)\n",
    "    events = load_tb_events(events_files, handle_dup_steps='keep-last')\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('../models_neural/quote_attribution/model_output/test/default/version_1/hparams.yaml').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_file = '../models_neural/quote_attribution/model_output/test/default/version_1/events.out.tfevents.1665523753.C02CJKQ2MD6M.57385.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbparse import SummaryReader\n",
    "reader = SummaryReader(file_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stage 2: Quote Attribution + Detection. Classification. Method 2. Our full dataset only. No train on None.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(reader\n",
    " .hparams\n",
    " .loc[lambda df: df['tag'] == 'notes']['value'].iloc[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Training Loss\n",
       "2647      Training f1 score\n",
       "2657    Validation f1 score\n",
       "2667        Validation loss\n",
       "2677                  epoch\n",
       "5344              hp_metric\n",
       "Name: tag, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.scalars['tag'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>tag</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>13236</td>\n",
       "      <td>Validation f1 score</td>\n",
       "      <td>0.414414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>26473</td>\n",
       "      <td>Validation f1 score</td>\n",
       "      <td>0.414414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>39710</td>\n",
       "      <td>Validation f1 score</td>\n",
       "      <td>0.414414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>52947</td>\n",
       "      <td>Validation f1 score</td>\n",
       "      <td>0.414414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>66184</td>\n",
       "      <td>Validation f1 score</td>\n",
       "      <td>0.700997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>79421</td>\n",
       "      <td>Validation f1 score</td>\n",
       "      <td>0.738318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>92658</td>\n",
       "      <td>Validation f1 score</td>\n",
       "      <td>0.731013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>105895</td>\n",
       "      <td>Validation f1 score</td>\n",
       "      <td>0.713128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>119132</td>\n",
       "      <td>Validation f1 score</td>\n",
       "      <td>0.694491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>132369</td>\n",
       "      <td>Validation f1 score</td>\n",
       "      <td>0.721154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        step                  tag     value\n",
       "2657   13236  Validation f1 score  0.414414\n",
       "2658   26473  Validation f1 score  0.414414\n",
       "2659   39710  Validation f1 score  0.414414\n",
       "2660   52947  Validation f1 score  0.414414\n",
       "2661   66184  Validation f1 score  0.700997\n",
       "2662   79421  Validation f1 score  0.738318\n",
       "2663   92658  Validation f1 score  0.731013\n",
       "2664  105895  Validation f1 score  0.713128\n",
       "2665  119132  Validation f1 score  0.694491\n",
       "2666  132369  Validation f1 score  0.721154"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.scalars.loc[lambda df: df['tag'] == 'Validation f1 score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_hparams_/session_end_info'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'protobuf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7a8f51706131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mprotobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'protobuf'"
     ]
    }
   ],
   "source": [
    "import protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = get_events(1, path_to_output + '/test/default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hp_metric':       value\n",
       " step       \n",
       " 0      -1.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='../models_neural/quote_attribution/model_output/version_10/events.out.tfevents.1665116328.compute-2dgtl-1665115287.1.0' mode='r' encoding='utf-8'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
