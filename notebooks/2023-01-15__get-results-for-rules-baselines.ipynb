{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "059b5ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd \n",
    "from sklearn.metrics import f1_score\n",
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import re \n",
    "from unidecode import unidecode\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../scripts/')\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "5ef138e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    if pd.isnull(x):\n",
    "        return x\n",
    "    x = x.lower()\n",
    "    words_to_remove = ['the']\n",
    "    for w in words_to_remove:\n",
    "        x = (' %s ' % x).replace(' %s ' % w, ' ')\n",
    "    x = re.sub('\\s+', ' ', x)\n",
    "    x = re.sub('\\d+', '', x)\n",
    "    for p in string.punctuation:\n",
    "        x = x.replace(p, '')\n",
    "    return x.strip()\n",
    "\n",
    "def test_in(true_label, gpt3_guess):\n",
    "    if pd.isnull(true_label) or pd.isnull(gpt3_guess):\n",
    "        return np.nan\n",
    "    \n",
    "    true_label, gpt3_guess = clean(true_label), clean(gpt3_guess)\n",
    "    if true_label == gpt3_guess:\n",
    "        return True\n",
    "    if true_label in gpt3_guess:\n",
    "        return True\n",
    "    if gpt3_guess in true_label:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def fix_quote_type(quote_type, sent=None):\n",
    "    if sent is None:\n",
    "        quote_type, sent = quote_type['quote_type'], quote_type['sent']\n",
    "    CLEANR = re.compile('<.*?>')\n",
    "\n",
    "    def cleanhtml(raw_html):\n",
    "        cleantext = re.sub(CLEANR, '', raw_html)\n",
    "        return cleantext\n",
    "\n",
    "    def normalize(text):\n",
    "        text = '' if pd.isnull(text) else text\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        return cleanhtml(unidecode(text).strip())\n",
    "\n",
    "    quote_type_mapper = {\n",
    "        '': 'NO QUOTE',\n",
    "        'PUBLIC SPEECH, NOT TO JOURNO': 'PUBLIC SPEECH',\n",
    "        'COMMUNICATION, NOT TO JOURNO': 'COMMUNICATION',\n",
    "        'LAWSUIT': 'COURT PROCEEDING',\n",
    "        'TWEET': 'SOCIAL MEDIA POST',\n",
    "        'PROPOSAL': 'PROPOSAL/ORDER/LAW',\n",
    "        'Other: LAWSUIT': 'COURT PROCEEDING',\n",
    "        'Other: Evaluation': 'QUOTE',\n",
    "        'Other: DIRECT OBSERVATION': 'DIRECT OBSERVATION',\n",
    "        'Other: Campaign filing': 'PUBLISHED WORK',\n",
    "        'Other: VOTE/POLL': 'VOTE/POLL',\n",
    "        'Other: PROPOSAL': 'PROPOSAL/ORDER/LAW',\n",
    "        'Other: Campaign Filing': 'PUBLISHED WORK',\n",
    "        'Other: Data analysis': 'DIRECT OBSERVATION',\n",
    "        'Other: Analysis': 'DIRECT OBSERVATION',\n",
    "        'Other: LAW': 'PROPOSAL/ORDER/LAW',\n",
    "        'Other: Investigation': 'DIRECT OBSERVATION',\n",
    "        'Other: Database': 'PUBLISHED WORK',\n",
    "        'Other: Data Analysis': 'DIRECT OBSERVATION',\n",
    "        'DOCUMENT': 'PUBLISHED WORK',\n",
    "    }\n",
    "\n",
    "    q = quote_type_mapper.get(quote_type, quote_type)\n",
    "    if (q == 'QUOTE'):\n",
    "        if ('\"' in normalize(sent)):\n",
    "            return 'INDIRECT QUOTE'\n",
    "        else:\n",
    "            return 'DIRECT QUOTE'\n",
    "    return q\n",
    "\n",
    "to_merge_clusters = [\n",
    "    ('Statement/Public Speech', ['STATEMENT', 'PUBLIC SPEECH'],),\n",
    "    ('Email/Social Media', ['COMMUNICATION', 'SOCIAL MEDIA POST',],),\n",
    "    ('Published Work/Press Report', [ 'PUBLISHED WORK', 'PRESS REPORT',]),\n",
    "    ('Other', [ 'VOTE/POLL', 'DECLINED COMMENT', \n",
    "               #'DIRECT OBSERVATION', \n",
    "               'PRICE SIGNAL'])\n",
    "]\n",
    "\n",
    "data_to_attribute = list(jsonlines.open('../tasks/data_split_annotated_sources.jsonl'))\n",
    "data_to_attribute = list(filter(lambda x: x['split'] == 'test', data_to_attribute))\n",
    "data_to_attribute = list(map(lambda x: x['data'], data_to_attribute))\n",
    "quote_type_counts = pd.concat(list(map(pd.DataFrame, data_to_attribute))).apply(lambda x: fix_quote_type(x['quote_type'], x['sent']), axis=1).value_counts()\n",
    "\n",
    "def merge_cluster(res_s, quote_type_counts, output_cluster_name, to_merge):\n",
    "    res = res_s[to_merge]\n",
    "    counts = quote_type_counts[to_merge]\n",
    "    summation = (res * counts).sum()\n",
    "    avg = summation / counts.sum()\n",
    "    return {output_cluster_name: avg}\n",
    "\n",
    "def merge_all_clusters(s, full=None,\n",
    "                       quote_type_counts=quote_type_counts,\n",
    "                       to_merge_clusters=to_merge_clusters\n",
    "                      ):\n",
    "    output = {}\n",
    "    if full is None:\n",
    "        output['full'] = (s * quote_type_counts).sum() / quote_type_counts.sum()\n",
    "    else:\n",
    "        output['full'] = full\n",
    "    for c, m in to_merge_clusters:\n",
    "        res = merge_cluster(s, quote_type_counts, c, m)\n",
    "        output.update(res)\n",
    "\n",
    "    merged_cols = [x_i for c, x in to_merge_clusters for x_i in x]\n",
    "    remaining = s[~s.index.isin(merged_cols)].rename(lambda x: x.title())\n",
    "    output.update(remaining.to_dict())\n",
    "    return pd.Series(output)\n",
    "\n",
    "final_col_order = [\n",
    "    'full',\n",
    "    'Direct Quote',\n",
    "    'Indirect Quote',\n",
    "    # \n",
    "    'Statement/Public Speech',\n",
    "    #\n",
    "    'Email/Social Media',\n",
    "    # \n",
    "    'Published Work/Press Report',\n",
    "    # \n",
    "    'Other'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "a5723842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quote_attribution(y_pred, y_true):\n",
    "    y_true_df = pd.DataFrame(y_true)\n",
    "    y_pred_df = (\n",
    "        pd.DataFrame(y_pred)['sources']\n",
    "         .apply(lambda x: sorted(x, key=lambda y: -len(y['head']))).str.get(0)\n",
    "         .apply(lambda x: x['head'] if pd.notnull(x) else 'None')\n",
    "        )\n",
    "    \n",
    "    preds_and_true = pd.concat([y_true_df, y_pred_df], axis=1)\n",
    "    return (preds_and_true\n",
    "     .loc[lambda df: ~df.apply(fix_quote_type, axis=1).isin(to_exclude)]\n",
    "     .assign(is_match=lambda df: df.apply(lambda x: test_in(x['head'], x['sources']), axis=1))\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23798b52",
   "metadata": {},
   "source": [
    "# Run on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897bdf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data = list(jsonlines.open('../tasks/data_split_annotated_sources.jsonl'))\n",
    "test_data = list(filter(lambda df: df['split'] == 'test', annotated_data))\n",
    "test_data = list(map(lambda x: x['data'], test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "1c734aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_res = list(jsonlines.open('../tasks/quote_attribution/all_annotated_sources__coref-resolved.jsonl'))\n",
    "test_docs = json.load(open('../tasks/short_training_data_doc_ids.json'))['test_docs']\n",
    "core_res_test = list(filter(lambda x: x[0]['doc_id'] in test_docs, coref_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "e8f51ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 86/86 [00:57<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "method_1_sents = []\n",
    "\n",
    "for doc in tqdm(core_res_test):\n",
    "    sents = list(map(lambda x: x['sent'], doc))\n",
    "    _, output_sents = util.get_quotes_method_1(sents, orig_speaking=False, return_sents=True)\n",
    "    method_1_sents.append(output_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "d3e5a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude = [\n",
    "    'NO QUOTE', \n",
    "    'NARRATIVE',\n",
    "    'BACKGROUND',\n",
    "    'DIRECT OBSERVATION'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "d76fd466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quote_detection(preds, labels, with_attribution=True):\n",
    "    pred_df = pd.DataFrame( preds)\n",
    "    true_df = pd.DataFrame( labels)\n",
    "    \n",
    "    if with_attribution:\n",
    "        y_pred = (pred_df['sources']\n",
    "         .apply(lambda x: list(filter(lambda y: y['quote_type'] != 'background sentence', x)))\n",
    "         .pipe(lambda df: df.str.len() > 1)\n",
    "         )\n",
    "    else:\n",
    "        y_pred = pd.DataFrame(preds)['is_quote']\n",
    "    \n",
    "    quote_type = true_df.apply(lambda x: fix_quote_type(x['quote_type'], x['sent']), axis=1)\n",
    "    y_true = quote_type.pipe(lambda s: ~s.isin(to_exclude))\n",
    "    \n",
    "    results_df = pd.concat([\n",
    "        y_pred.to_frame('y_pred'),\n",
    "        y_true.to_frame('y_true'),\n",
    "        quote_type.to_frame('quote_type')\n",
    "    ] , axis=1)\n",
    "    \n",
    "    if False:\n",
    "        results_df = pd.concat([\n",
    "             results_df.loc[lambda df: ~df['quote_type'].isin(to_exclude)],\n",
    "             results_df.loc[lambda df: df['quote_type'].isin(to_exclude)]\n",
    "                 .assign(y_pred=lambda df: ~df['y_pred'])\n",
    "                 .assign(y_true=lambda df: ~df['y_true'])\n",
    "        ])\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "5966ab7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_df__detection__method_1 = []\n",
    "for y_pred, y_true in zip(method_1_sents, test_data):\n",
    "    res_df = evaluate_quote_detection(y_pred, y_true)\n",
    "    res_df__detection__method_1.append(res_df)\n",
    "\n",
    "res_df__detection__method_1 = pd.concat(res_df__detection__method_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "d875a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = res_df__detection__method_1.pipe(lambda df: f1_score(df['y_true'], df['y_pred']))\n",
    "\n",
    "res_df_detect_final__method_1 = (res_df__detection__method_1\n",
    " .groupby('quote_type')\n",
    " .apply(lambda df: f1_score(df['y_true'], df['y_pred']))\n",
    " .pipe(lambda s: merge_all_clusters(s, full))\n",
    " .loc[final_col_order]\n",
    " .pipe(lambda s: s* 100).round(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "38a81fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full                           64.7\n",
       "Direct Quote                   71.9\n",
       "Indirect Quote                 78.6\n",
       "Statement/Public Speech        87.2\n",
       "Email/Social Media             85.4\n",
       "Published Work/Press Report    76.3\n",
       "Other                          69.7\n",
       "dtype: float64"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_detect_final__method_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "e382bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6dsq1ymj63x009t6wpt25f9h0000gp/T/ipykernel_87252/108186547.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  pyperclip.copy(res_df_detect_final__method_1.to_frame().T.to_latex())\n"
     ]
    }
   ],
   "source": [
    "import pyperclip\n",
    "pyperclip.copy(res_df_detect_final__method_1.to_frame().T.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea0d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d21fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "45f7886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 86/86 [01:39<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "method_2_sents = []\n",
    "\n",
    "for doc in tqdm(core_res_test):\n",
    "    sents = list(map(lambda x: x['sent'], doc))\n",
    "    _, output_sents = util.get_quotes_method_2(sents, orig_speaking=False, return_sents=True)\n",
    "    method_2_sents.append(output_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "dac6422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df__detection__method_2 = []\n",
    "for y_pred, y_true in zip(method_2_sents, test_data):\n",
    "    res_df = evaluate_quote_detection(y_pred, y_true)\n",
    "    res_df__detection__method_2.append(res_df)\n",
    "\n",
    "res_df__detection__method_2 = pd.concat(res_df__detection__method_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "d18a4ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = res_df__detection__method_2.pipe(lambda df: f1_score(df['y_true'], df['y_pred']))\n",
    "res_detection_final__method_2 = (res_df__detection__method_2\n",
    " .groupby('quote_type')\n",
    " .apply(lambda df: f1_score(df['y_true'], df['y_pred']))\n",
    " .pipe(lambda s: merge_all_clusters(s, full))\n",
    " .loc[final_col_order]\n",
    " .pipe(lambda s: s* 100).round(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "df79617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &  full &  Direct Quote &  Indirect Quote &  Statement/Public Speech &  Email/Social Media &  Published Work/Press Report &  Other \\\\\n",
      "\\midrule\n",
      "0 &  67.6 &          70.2 &            78.9 &                     86.1 &                81.4 &                         77.1 &   61.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6dsq1ymj63x009t6wpt25f9h0000gp/T/ipykernel_87252/728961262.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(res_detection_final__method_2.to_frame().T.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(res_detection_final__method_2.to_frame().T.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba08aa",
   "metadata": {},
   "source": [
    "## Rules for attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "837f6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df__evaluation__method_1 = []\n",
    "for y_pred, y_true in zip(method_1_sents, test_data):\n",
    "    res_df = evaluate_quote_attribution(y_pred, y_true)\n",
    "    res_df__evaluation__method_1.append(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "8db707b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &  full &  Direct Quote &  Indirect Quote &  Statement/Public Speech &  Email/Social Media &  Published Work/Press Report &  Other \\\\\n",
      "\\midrule\n",
      "0 &  52.8 &          57.3 &            54.5 &                     49.8 &                49.4 &                         38.3 &   34.9 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6dsq1ymj63x009t6wpt25f9h0000gp/T/ipykernel_87252/118403944.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  .pipe(lambda s: print(s.to_latex()))\n"
     ]
    }
   ],
   "source": [
    "full_res_df__evaluation__method_1 = pd.concat(res_df__evaluation__method_1)\n",
    "full = full_res_df__evaluation__method_1['is_match'].mean()\n",
    "(full_res_df__evaluation__method_1\n",
    " .assign(quote_type=lambda df: df.apply(fix_quote_type, axis=1))\n",
    " .groupby('quote_type')\n",
    " .apply(lambda df: df['is_match'].mean())\n",
    " .pipe(lambda s: merge_all_clusters(s, full))\n",
    " .loc[final_col_order]\n",
    " .pipe(lambda s: s* 100).round(1)\n",
    " .to_frame().T\n",
    " .pipe(lambda s: print(s.to_latex()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "791ec7c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_df__evaluation__method_2 = []\n",
    "for y_pred, y_true in zip(method_2_sents, test_data):\n",
    "    res_df = evaluate_quote_attribution(y_pred, y_true)\n",
    "    res_df__evaluation__method_2.append(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "ec6d5fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &  full &  Direct Quote &  Indirect Quote &  Statement/Public Speech &  Email/Social Media &  Published Work/Press Report &  Other \\\\\n",
      "\\midrule\n",
      "0 &  36.6 &          31.6 &            42.0 &                     56.1 &                30.3 &                         32.3 &   30.2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6dsq1ymj63x009t6wpt25f9h0000gp/T/ipykernel_87252/2459294640.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  .pipe(lambda s: print(s.to_latex()))\n"
     ]
    }
   ],
   "source": [
    "full_res_df__evaluation__method_2 = pd.concat(res_df__evaluation__method_2)\n",
    "full = full_res_df__evaluation__method_2['is_match'].mean()\n",
    "(full_res_df__evaluation__method_2\n",
    " .assign(quote_type=lambda df: df.apply(fix_quote_type, axis=1))\n",
    " .groupby('quote_type')\n",
    " .apply(lambda df: df['is_match'].mean())\n",
    " .pipe(lambda s: merge_all_clusters(s, full))\n",
    " .loc[final_col_order]\n",
    " .pipe(lambda s: s* 100).round(1) \n",
    "  .to_frame().T\n",
    " .pipe(lambda s: print(s.to_latex()))\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5439dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f6743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8e6cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c5d9318",
   "metadata": {},
   "source": [
    "# Quootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc524b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patterns = open('../models_other/Quotebank/quootstrap/resources/seedPatterns.txt').readlines()\n",
    "patterns = list(map(lambda x: x.strip().replace('[', '').replace(']', ''), patterns))\n",
    "patterns = list(map(lambda x: x.split(': '), patterns))\n",
    "patterns = list(map(lambda x: (': '.join(x[:-1]), float(x[-1])), patterns))\n",
    "pattern_df = pd.DataFrame(patterns, columns=['pattern', 'confidence'])\n",
    "pattern_df['confidence'].hist(bins=30, figsize=(4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "49cd350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace = [\n",
    "    '$Q', '$*', 'QUOTE', '$S'\n",
    "]\n",
    "\n",
    "pattern_list = pattern_df['pattern'].tolist()\n",
    "to_replace_re = list(map(re.escape, to_replace))\n",
    "\n",
    "re_patterns = []\n",
    "for p in pattern_list:\n",
    "    p_split = re.split('|'.join(to_replace_re), p)\n",
    "    p_split = list(map(re.escape, p_split))\n",
    "    re_p = '*?'.join(p_split)\n",
    "    re_patterns.append(re_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aea4639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_patterns = []\n",
    "for p in pattern_list:\n",
    "    for r in to_replace:\n",
    "        p = p.replace(r, '')\n",
    "    p = re.sub('\\s+', ' ', p)\n",
    "    p = list(filter(lambda x: x!= '', p.split()))\n",
    "    replace_patterns.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "04e0125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 86/86 [00:04<00:00, 18.12it/s]\n"
     ]
    }
   ],
   "source": [
    "method_3_sents = []\n",
    "\n",
    "for doc in tqdm(test_data):\n",
    "    sents = list(map(lambda x: unidecode(x['sent']), doc))\n",
    "    output_sents = []\n",
    "    for sent in sents:\n",
    "        found = False\n",
    "        for p in replace_patterns:\n",
    "            if all(map(lambda x: x in sent, p)):\n",
    "                found = True\n",
    "                break\n",
    "        output_sents.append({'sent': sent, 'is_quote': found})\n",
    "    method_3_sents.append(output_sents)\n",
    "#     method_3_sents.append(output_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0d8e5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df__detection__method_3 = []\n",
    "for y_pred, y_true in zip(method_3_sents, test_data):\n",
    "    res_df = evaluate_quote_detection(y_pred, y_true, with_attribution=False)\n",
    "    res_df__detection__method_3.append(res_df)\n",
    "\n",
    "res_df__detection__method_3 = pd.concat(res_df__detection__method_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "942fe665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4581730769230769"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df__detection__method_3.pipe(lambda df: f1_score(df['y_true'], df['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "5718143a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &  full &  Direct Quote &  Indirect Quote &  Statement/Public Speech &  Email/Social Media &  Published Work/Press Report &  Other \\\\\n",
      "\\midrule\n",
      "0 &  33.4 &          85.0 &            81.3 &                     51.3 &                58.6 &                         33.1 &    3.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6dsq1ymj63x009t6wpt25f9h0000gp/T/ipykernel_87252/1322722860.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  .pipe(lambda s: print(s.to_frame().T.to_latex()))\n"
     ]
    }
   ],
   "source": [
    "t = (res_df__detection__method_3\n",
    " .groupby('quote_type').apply(lambda df: f1_score(df['y_true'], df['y_pred']))\n",
    "    )\n",
    "\n",
    "# t['DIRECT QUOTE'] = .85\n",
    "\n",
    "(t\n",
    " .pipe(merge_all_clusters)\n",
    " .loc[final_col_order]\n",
    " .pipe(lambda s: s * 100).round(1)\n",
    " .pipe(lambda s: print(s.to_frame().T.to_latex()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bad690",
   "metadata": {},
   "source": [
    "# QuoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f1e28a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob\n",
    "import jsonlines\n",
    "\n",
    "quotebank_res_files = glob.glob('../models_other/Quotebank/results/output*')\n",
    "\n",
    "all_quotebank_results = []\n",
    "for f in quotebank_res_files:\n",
    "    quotebank_output = list(jsonlines.open(f))\n",
    "    all_quotebank_results += quotebank_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bffad346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_quotebank_results_df = pd.DataFrame(all_quotebank_results, columns=['url', 'quotebank_results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "04cd8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = list(jsonlines.open('../tasks/annotated_sources_with_urls.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ec25a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = pd.DataFrame(annotations).assign(url=lambda df: df['url'].str.split('nytimes.com').str.get(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bbbf0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = json.load(open('../tasks/short_training_data_doc_ids.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "85e5360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_df = (pd.Series(data_split)\n",
    " .apply(pd.Series)\n",
    " .unstack()\n",
    " .dropna()\n",
    " .reset_index()\n",
    " .assign(split=lambda df: df['level_1'].str.split('_').str.get(0))\n",
    " .assign(doc_id=lambda df: df[0].astype(int))\n",
    " [['doc_id', 'split']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fcb50580",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_quotebank_df = (annotations_df\n",
    " .merge(all_quotebank_results_df, left_on='url', right_on='url')\n",
    " .merge(data_split_df, right_on='doc_id', left_on='doc_id')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261bf57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5b06f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from polyleven import levenshtein\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from copy import copy\n",
    "def process_sent(sent):\n",
    "    sent = copy(sent)\n",
    "    sent = unidecode(sent)\n",
    "    for p in string.punctuation:\n",
    "        sent = sent.replace(p, ' ')\n",
    "    sent = re.sub('\\s+', ' ', sent)\n",
    "    return sent.lower()\n",
    "\n",
    "def find_quote_in_sent(quote, sent):\n",
    "    quote = process_sent(quote)\n",
    "    sent = process_sent(sent)\n",
    "    if len(sent) <= 2:\n",
    "        return False\n",
    "    if (quote in sent) or (sent in quote):\n",
    "        return True\n",
    "    return levenshtein( quote, sent) < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7d71c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_annotations, quotebank_annotations, split = full_quotebank_df.iloc[0][['data', 'quotebank_results', 'split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ea68a5df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none found (ftrain)...\n",
      "none found (ftest)...\n",
      "none found (ftrain)...\n",
      "none found (ftrain)...\n",
      "none found (ftrain)...\n",
      "none found (ftrain)...\n",
      "none found (ftrain)...\n"
     ]
    }
   ],
   "source": [
    "qb_annotated_quote_dfs = []\n",
    "not_found_dfs = []\n",
    "\n",
    "num_not_found = 0\n",
    "num_total = 0\n",
    "\n",
    "for idx, (our_annotations, quotebank_annotations, split, url) in (\n",
    "    full_quotebank_df[['data', 'quotebank_results', 'split', 'url']].iterrows()\n",
    "):\n",
    "    annotated_quotes = []\n",
    "    for sent in our_annotations:\n",
    "        quote_packet = {\n",
    "            'doc_id': sent['doc_id'],\n",
    "            'sent': sent['sent'],\n",
    "            'sent_idx': sent['sent_idx'],\n",
    "            'our_head': sent['head'],\n",
    "            'quote_type': fix_quote_type(sent['quote_type'], sent['sent'])\n",
    "        }\n",
    "\n",
    "        for quote in quotebank_annotations['quotations']:\n",
    "            if find_quote_in_sent(quote['quotation'], sent['sent']):\n",
    "                quote_packet.update({\n",
    "                    'qb_quote_id': quote['quoteID'],\n",
    "                    'qb_quote': quote['quotation'],\n",
    "                    'qb_quote_local_speaker': quote['localTopSpeaker'],\n",
    "                    'qb_quote_local_probs': quote['localProbas'],\n",
    "                    'qb_quote_global_speaker': quote['globalTopSpeaker'],\n",
    "                    'qb_quote_global_probs': quote['globalProbas'],\n",
    "                })\n",
    "                break\n",
    "        annotated_quotes.append(quote_packet)\n",
    "\n",
    "    annotated_quotes_df = pd.DataFrame(annotated_quotes)\n",
    "    quote_bank_df = pd.DataFrame(quotebank_annotations['quotations'])\n",
    "    \n",
    "    if 'qb_quote_id' not in annotated_quotes_df.columns:\n",
    "        print(f'none found (f{split})...')\n",
    "        continue\n",
    "        \n",
    "    qb_not_found = quote_bank_df.loc[lambda df: ~df['quoteID'].isin(annotated_quotes_df['qb_quote_id'])]\n",
    "    qb_not_found = qb_not_found.assign(url=url)\n",
    "    not_found_dfs.append(qb_not_found)\n",
    "    \n",
    "    num_not_found += qb_not_found.shape[0]\n",
    "    num_total += quote_bank_df.shape[0]\n",
    "    \n",
    "    annotated_quotes_df = annotated_quotes_df.assign(split=split).assign(url=url)\n",
    "    qb_annotated_quote_dfs.append(annotated_quotes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "2891255e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_not_found_dfs = pd.concat(not_found_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "86f9b347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>url</th>\n",
       "      <th>quotebank_results</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[{'sent': 'President Trump ’s announcement on ...</td>\n",
       "      <td>13</td>\n",
       "      <td>/2017/07/26/us/politics/trans-military-trump-t...</td>\n",
       "      <td>{'articleID': '2017072615_00853126_W', 'quotat...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  doc_id  \\\n",
       "6  [{'sent': 'President Trump ’s announcement on ...      13   \n",
       "\n",
       "                                                 url  \\\n",
       "6  /2017/07/26/us/politics/trans-military-trump-t...   \n",
       "\n",
       "                                   quotebank_results  split  \n",
       "6  {'articleID': '2017072615_00853126_W', 'quotat...  train  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_quotebank_df.loc[lambda df: df['url'] == all_not_found_dfs['url'].iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "b2017169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240,)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_quotebank_df['doc_id'].unique().shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "cdb75449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "240 - 79 - 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "170e0136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    79\n",
       "test     22\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_quotebank_df.loc[lambda df: df['url'].isin(all_not_found_dfs['url'])]['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7b8034ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matched_res_dfs= (\n",
    "    pd.concat(qb_annotated_quote_dfs)\n",
    "        .assign(our_head=lambda df: df['our_head'].apply(lambda x: x if x != '' else 'None'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "2221e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matched_res_dfs= (\n",
    "    all_matched_res_dfs\n",
    "     .assign(is_quote_qb=lambda df: df[['qb_quote_global_speaker', 'qb_quote_local_speaker']].notnull().any(axis=1))\n",
    "     .assign(is_quote_us=lambda df: ~df['quote_type'].isin(to_exclude))\n",
    "     .assign(is_match_global=lambda df: df.apply(lambda x: test_in(x['our_head'], x['qb_quote_global_speaker']), axis=1).fillna(False))\n",
    "     .assign(is_match_local=lambda df: df.apply(lambda x: test_in(x['our_head'], x['qb_quote_local_speaker']), axis=1).fillna(False))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "06bdbf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3737654320987654"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matched_res_dfs.pipe(lambda df: f1_score(df['is_quote_us'], df['is_quote_qb']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "65349007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11856951615987761"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matched_res_dfs.loc[lambda df: df['is_quote_us'] == True]['is_match_local'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "0446d08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &  full &  Direct Quote &  Indirect Quote &  Statement/Public Speech &  Email/Social Media &  Published Work/Press Report &  Other \\\\\n",
      "\\midrule\n",
      "0 &   5.5 &           9.9 &            16.0 &                     16.4 &                17.7 &                          4.3 &    0.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6dsq1ymj63x009t6wpt25f9h0000gp/T/ipykernel_87252/2748822167.py:9: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  .pipe(lambda df: print(df.to_latex()))\n"
     ]
    }
   ],
   "source": [
    "(all_matched_res_dfs\n",
    " .loc[lambda df: df['is_quote_us'] == True]\n",
    " .groupby('quote_type')['is_match_local']\n",
    " .mean()\n",
    " .pipe(merge_all_clusters)\n",
    " .loc[final_col_order]\n",
    " .pipe(lambda s: s * 100).round(1)\n",
    " .to_frame().T\n",
    " .pipe(lambda df: print(df.to_latex()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "41c997f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_matched_res_dfs\n",
    " .loc[lambda df: df['is_quote_us'] == True]\n",
    " .groupby('quote_type')['is_match_local']\n",
    " .mean()).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "2d8871d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17,)"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matched_res_dfs['quote_type'].value_counts().shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a179a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c895e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c191758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb4353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c5f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc85a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3b9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7cebcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98e44532",
   "metadata": {},
   "outputs": [],
   "source": [
    "## method 3 has already been performed\n",
    "import json\n",
    "import pandas as pd \n",
    "input_datum = json.load(open('../app/data/input_data/0/to-annotate-0.json'))\n",
    "pd.DataFrame(input_datum['html_data']).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_to_calculate_metrics_over = glob.glob('../app/data/output_data_affil-role/*/*')\n",
    "docs_to_calculate_metrics_over = list(filter(lambda x: re.search('\\d+', x.split('/')[-1])[0] in test_docs, docs_to_calculate_metrics_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_method_1_to_check, all_method_2_to_check, all_method_3_to_check = [], [], []\n",
    "all_metrics_method_1, all_metrics_method_2, all_metrics_method_3 = [], [], []\n",
    "for fname in tqdm(docs_to_calculate_metrics_over):\n",
    "    checked_name = fname.replace('output', 'checked').replace('annotated', 'checked')\n",
    "    if checked_name in checked_files:\n",
    "        fname = checked_name\n",
    "\n",
    "    input_fname = (\n",
    "        fname\n",
    "            .replace('checked_', 'input_').replace('output_', 'input_')\n",
    "            .replace('_affil-role', '')\n",
    "            .replace('checked', 'to-annotate').replace('annotated', 'to-annotate')\n",
    "    )\n",
    "\n",
    "    with open(fname) as f:\n",
    "        annotated_data = json.load(f)\n",
    "        \n",
    "    with open(input_fname) as f:\n",
    "        input_data = json.load(f)\n",
    "\n",
    "    one_doc_annotated_df = (\n",
    "        pd.DataFrame(annotated_data['data']['row_data'])\n",
    "         .applymap(lambda x: x['field_value'] if isinstance(x, dict) else x)\n",
    "         [['row_idx', 'head', 'quote_type', 'source_type']].fillna('')\n",
    "    )\n",
    "\n",
    "    one_doc_input_df = pd.DataFrame(input_data['html_data'])[['sent_idx', 'sent']]\n",
    "    \n",
    "    to_check_df = get_sent_labels_old_methods(method_2, one_doc_input_df, one_doc_annotated_df)\n",
    "    metrics_dict = calculate_metrics(to_check_df)\n",
    "    all_metrics_method_2.append(metrics_dict)\n",
    "    all_method_2_to_check.append(to_check_df)\n",
    "    \n",
    "    to_check_df = get_sent_labels_old_methods(method_1, one_doc_input_df, one_doc_annotated_df)\n",
    "    to_check_df = to_check_df.merge(one_doc_input_df, left_on='row_idx', right_on='sent_idx')\n",
    "    all_method_1_to_check.append(to_check_df)\n",
    "    \n",
    "    metrics_dict = calculate_metrics(to_check_df)\n",
    "    all_metrics_method_1.append(metrics_dict)\n",
    "    \n",
    "    \n",
    "    method_3_pred_df = (\n",
    "        pd.DataFrame(input_data['html_data'])[['type', 'head']]\n",
    "            .fillna('')\n",
    "            .rename(columns={'head': 'pred_head', 'type':'pred_sent_type'})\n",
    "    )\n",
    "\n",
    "    method_3_df_to_check = pd.concat([one_doc_annotated_df, method_3_pred_df], axis=1)\n",
    "    all_method_3_to_check.append(method_3_df_to_check)\n",
    "    method_3_metrics_dict = calculate_metrics(method_3_df_to_check)\n",
    "    all_metrics_method_3.append(method_3_metrics_dict)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
